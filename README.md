# AI-News
Welcome to the Weekly-AI-news!
I mainly focuses more on Generative AI, LLMs and the related, so may miss import AI news in other areas.


**23 July 2023**
1.	A recent [report from OpenUK](https://openuk.uk/wp-content/uploads/2023/07/FINAL-State-of-Open-The-UK-in-2023-Phase-Two-Part-1.pdf) indicates that in 2022, the Gross Value added to the UK economy from Open Source Software is estimated to be £13.59 billion. So what does that mean? Contextualising it with the UK Tech Sector contribution at £50 billion in 2022, the directly attributable contribution from Open Source Software is therefore 27%, more than a quarter of the overall Tech Sector contribution.
2.	17 Jul, Microsoft published a [paper](https://arxiv.org/abs/2307.08621): “Retentive Network: A Successor to Transformer for Large Language Models”. RetNet achieves low-cost inference (i.e., GPU memory, throughput, and latency), training parallelism, and favorable scaling curves compared with Transformer. RetNet makes the “impossible triangle” possible, which achieves training parallelism, good performance, and low inference cost simultaneously. The code will be released within two weeks.
3.	17 Jul, [HPC-AI released its 65 billion](https://www.hpc-ai.tech/blog/large-model-pretraining) parameter large language model. It utilizes the current most widely used large model, LLaMA, to provide an example of the tool’s groundbreaking pre-training solutions for the 65 billion parameter large model which improves the training speed by 38%. This can save enormous amounts for large model enterprises. HPC-AI only needs 32 A100/A800 GPUs to improve pre-training speed by 38% compared to other mainstream options in the industry.
4.	18 Jul, Dao published a [paper](https://tridao.me/publications/flash2/flash2.pdf), FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning. FlashAttention2 (1) tweaks the algorithm to reduce the number of non-matmul FLOPs (2) parallelizes the attention computation, even for a single head, across different thread blocks to increase occupancy, and (3) within each thread block, distributes the work between warps to reduce communication through shared memory. These yield around2× speedup compared to FlashAttention, reaching 50-73% of the theoretical maximum FLOPs/s on A100 and getting close to the efficiency of GEMM operations.
5.	19 Jul, Meta [released LLaMA v2](https://download.llamameta.net/*?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiI0o%7EP01cdTAwMWUjPyIsIlJlc291cmNlIjoiaHR0cHM6XC9cL2Rvd25sb2FkLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODk4MTkzMzR9fX1dfQ__&Signature=CgIvdOxnfMPih1sAr%7EkkhBGpl0PBj9n9rebxjFEbb6u-aVLYyV1kK2le4B0bSt3jZ9gFFc2pf5XTG%7EauFCE4lo7FSiQ7VRRKIEjpTx9QtGzO%7EvquyTb3sON6YdEtLi4fu%7EBVYk58ce%7E5nK%7EkXvqsuld5zA%7EPaLKB-WXjd-6DwmqUjphv4k6v0Lb7jH0V%7EgCzK3JFuzUwrCUPXInbtDinMnCUPOFu4TW-%7E9QlZVPUaDfqlRvWExDcULe3akb2KEGif37U-P3fLTmrGdIuTSflvqJrUdM33FwbMd2a7s2TSIUcLBD%7EUqvyi43Drx2Cr8zzSFAOVYovwMQMYxUtUGrphQ__&Key-Pair-Id=K15QRJLYKIFSLZ), a series of large language models trained on 40% more data (2 Trillion tokens) than Llama 1, and has doubled the context length to 4096. Meta also provided finetuned dialog models with over 100k samples. Llama 2 outperforms other open source language models on many external benchmarks, including reasoning, coding, proficiency, and knowledge tests.
6.	19 Jul [Reuters reported](https://www.reuters.com/technology/apple-tests-generative-ai-tools-rival-openais-chatgpt-bloomberg-news-2023-07-19/) that Apple is working on AI offering similar to OpenAI’s ChatGPT and Google’s Bard, causing its shares up as much as 2% to a record high. Apple's new virtual assistant summarizes text and answers questions based on data it has been trained with, and the tool essentially replicates Bard, ChatGPT and Bing AI, and works as a web application, according to employees of Apple.
7.	19 Jul, researcher from UCL, EleutherAI, Meta, StabilityAI and others published a [paper](https://arxiv.org/pdf/2307.10169.pdf) “Challenges and Applications of Large Language Models”. The authors believed that due to the fast pace of the field, it is difficult to identify the remaining challenges and already fruitful application areas. They explored the challenges of LLMs from three views: Designing LLMs relates to decisions taken before deployment. Behaviorial challenges occur during deployment. Science challenges hinder academic progress.
8.	20 Jul, Nature published a [paper](https://www.nature.com/articles/d41586-023-02317-x) “How to introduce quantum computers without slowing economic growth”. The researchers 
believe that new ways of simulating materials, optimizing processes and improving machine learning — could transform society. They also suggested that Specialists should work together to create narratives around the usefulness of quantum technologies; however, the technology bottlenecks for quantum computing are unclear, and Would these benefits lead to more products and services that are better tailored to customer needs? What would the impacts be on the wider industrial landscape, and what new business models might emerge?
9.	21 Jul, [StabilityAI released FreeWilly](https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models), the large and mighty instruction finetuned open access language models (FreeWilly1 and FreeWilly2). FreeWilly1 leverages the original LLaMA 65B foundation model and was carefully fine-tuned with a new synthetically-generated dataset using Supervised Fine-Tune (SFT) in standard Alpaca format. Similarly, FreeWilly2 leverages the LLaMA 2 70B foundation model to reach a performance that compares favorably with GPT-3.5 for some tasks.
10.	21 Jul, [according to HDTECH](https://tech.hindustantimes.com/tech/news/sergey-brin-returns-to-google-to-work-on-secret-ai-project-gemini-71689927230676.html), Google’s cofounder Sergey Brin returns to Google to work on the secret AI project Gemini, the company’s highly ambitious general-purpose AI project. Gemini would be a multi-modal foundational model that powers other AI models but no further details are known at the moment.


**16 July 2023**
1. Jul 9 – 14, [ACL 2023](https://2023.aclweb.org/), Annual Meeting of the Association for Computational Linguistics (ACL), which is one of the top natural language processing conferences in the world, was held in Toronto, Canada.
2. Jul 11, Anthropic AI released [Claude 2](https://www.anthropic.com/index/claude-2), Claude 2 has improved performance, longer responses, and can be accessed via API as well as a new public-facing beta website, claude.ai. The latest model scored 76.5% on the multiple choice section of the Bar exam, up from 73.0% with Claude 1.3.
3. Jul 11, according to [Bloomberg](https://www.bloomberg.com/news/articles/2023-07-11/ai-researcher-who-helped-write-landmark-paper-is-leaving-google), AI Researcher Who Helped Write Landmark Paper Is Leaving Google, and the last one who is still working for Google, is departing Google, and will start a company after taking time off.
4. Jul 12, Elon Musk announced [xAI](https://x.ai/), is to understand the true nature of the universe. The new team members have previously worked at DeepMind, OpenAI, Google Research, Microsoft Research, Tesla, and the University of Toronto. Collectively the team contributed some of the most widely used methods in the field, in particular the Adam optimizer, Batch Normalization, Layer Normalization, and the discovery of adversarial examples. xAI aims at implement AGI by the end of 2029, the due date.
5. Jul 12, [businessinsider reported](https://www.businessinsider.com/ai-could-run-out-text-train-chatbots-chatgpt-llm-2023-7) that UC Berkly prof. Stuart Russell warned that AI developers are "running out of text" to train chatbots at a UN summit, and AI's strategy behind training large language models is "starting to hit a brick wall." It also reported that a group of AI researchers, estimated that machine learning datasets will likely deplete all "high-quality language data" before 2026.
6. Jul 12, Google published a [paper on Nature](https://www.nature.com/articles/s41586-023-06291-2) “Large language models encode clinical knowledge”. The paper proposes a human evaluation framework for model answers along multiple axes including factuality, comprehension, reasoning, possible harm and bias. Using a combination of prompting strategies, Flan-PaLM achieves state-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA3, MedMCQA4, PubMedQA5 and Measuring Massive Multitask Language Understanding (MMLU) clinical topics6), including 67.6% accuracy on MedQA (US Medical Licensing Exam-style questions), surpassing the prior state of the art by more than 17%.
7. Jul 12, Nature published a [paper](https://www.nature.com/articles/s41586-023-06095-4) “Quantum-enhanced Markov chain Monte Carlo”. Researchers have developed a quantum algorithm that can sample from complicated distributions, such as MCMC, arising in several applications. This algorithm is well-suited to current hardware and could ease computational bottlenecks in machine learning, statistical physics, and optimization.
8. Jul 13, [Hashingtonpost reported](https://www.washingtonpost.com/technology/2023/07/13/ftc-openai-chatgpt-sam-altman-lina-khan/) that the Federal Trade Commission has opened an expansive investigation into OpenAI, probing whether the maker of the popular ChatGPT bot has run afoul of consumer protection laws by putting personal reputations and data at risk. The FTC’s demands of OpenAI are the first indication of how it intends to enforce those warnings. If the FTC finds that a company violates consumer protection laws, it can levy fines or put a business under a consent decree, which can dictate how the company handles data. The FTC in its request also asked the company to provide extensive details about its products and the way it advertises them. It also demanded details about the policies and procedures that OpenAI takes before it releases any new product to the public, including a list of times that OpenAI held back a large language model because of safety risks.
9. Jul 14, Meta published a [paper](https://ai.meta.com/research/publications/scaling-autoregressive-multi-modal-models-pretraining-and-instruction-tuning/) “Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning”. The new model, named CM3Leon, is a retrieval-augmented, tokenbased, decoder-only multi-modal language model capable of generating and infilling both text and images. CM3Leon achieves state-of-theart performance in text-to-image generation with 5x less training compute than
comparable methods.


**10 July 2023**
1. Last week, Salesforce released [XGen-7b](https://blog.salesforceairesearch.com/xgen/), which achieves comparable or better results when compared with state-of-the-art open-source LLMs (e.g. MPT, Falcon, LLaMA, Redpajama, OpenLLaMA) of similar model size, and its targeted evaluation on long sequence modeling benchmarks show benefits of our 8K-seq models over 2K- and 4K-seq models. Training cost of $150K on 1T tokens under Google Cloud pricing for TPU-v4.
2. 4th July, according to [iTnews](https://www.itnews.com.au/news/chatgpt-used-in-peer-reviews-of-australian-research-council-grant-applications-597596), ChatGPT is used in peer reviews of Australian Research Council grant applications. However, ARC warns that this could be a breach of confidentiality, and has since released a statement advising peer reviewers not to use AI as part of their assessments.
3. 4th July, OpenAI [announced](https://techcrunch.com/2023/07/06/openai-makes-gpt-4-generally-available/) to make GPT-4 API and Code Interpreter generally available to all paying API users. It also announced a deprecation plan for some old models which will retire in 2024.
4. On 5th July, a group of researchers published a [paper](https://arxiv.org/abs/2307.02053) “FLACUNA: Unleashing the Problem-Solving Power of VICUNA using FLAN Fine-Tuning”. The researchers constructed a new dataset comprising a large number of tasks that demand problem-solving skills. Experimental findings strongly indicate that the enhanced problem-solving abilities of  FLACUNA, are obtained through fine-tuning VICUNA on the FLAN dataset, leading to significant improvements across numerous benchmark datasets in INSTRUCTEVAL.
5. 5th July, Nature published a [paper](https://www.nature.com/articles/s41586-023-06185-3) “Accurate medium-range global weather forecasting with 3D neural networks”. The authors of the paper proposed that three-dimensional deep neural networks can be trained to forecast global weather patterns, including extreme weather, with accuracy greater than or equal to that of the best numerical weather prediction models.
6. 5th July, researchers from Microsoft published a [paper](https://arxiv.org/abs/2307.02486#:~:text=In%20this%20work%2C%20we%20introduce%20LongNet%2C%20a%20Transformer,the%20attentive%20field%20exponentially%20as%20the%20distance%20grows.) “LongNet: Scaling Transformers to 1,000,000,000 Tokens”. LongNet is a Transformer variant that can scale sequence length to more than 1 billion tokens, without sacrificing the performance on shorter sequences. Specifically, we propose dilated attention, which expands the attentive field exponentially as the distance grows.
7. 6th July, Google and others published a [paper](https://arxiv.org/abs/2307.03170#:~:text=To%20tackle%20this%20problem%2C%20we%20introduce%20the%20Focused,space%2C%20enabling%20an%20extension%20of%20the%20context%20length.) “Focused Transformer: Contrastive Training for Context Scaling”. The paper introduces the Focused Transformer (FoT), a technique that employs a training process inspired by contrastive learning. This novel approach enhances the structure of the (key, value) space, enabling an extension of the context length.
8. 7th July,  according to [Washingtontpost](https://www.washingtonpost.com/technology/2023/07/07/chatgpt-users-decline-future-ai-openai/) and [this report](https://www.livemint.com/technology/tech-news/chatgpt-faces-first-ever-monthly-traffic-decline-shows-shift-in-user-preferences-report-11688621775980.html), ChatGPT, the highly popular AI chatbot introduced in November, experienced a decline in its website's monthly traffic and unique visitors for the first time in June, as reported by Similarweb analytics.
9. 10th July, according to [TheVerge](https://www.theverge.com/2023/7/10/23787453/meta-instagram-threads-100-million-users-milestone), Instagram’s Threads app surpasses 100 million users within only 5 day since its release.


**2 July 2023**
1. 23rd Jun, [A16Z’s Shoham interviewed](https://a16z.com/2023/06/23/the-next-token-of-progress-4-unlocks-on-the-generative-ai-horizon/) CEOs from Anthropic, Cohere, Charater.AI, they identified four key innovations: Steering, memory, “arms and legs”, and multimodality; and how these key innovations will evolve over the next 6 to 12 months.
2. 26 Jun, [Wired reports](https://www.wired.com/story/google-deepmind-demis-hassabis-chatgpt/) that DeepMind’s CEO says its next AI project Gemini, is still under development within several months, will be more capable than OpenAI’s ChatGPT, including such as planning or the ability to solve problems. AlphaGo-type techniques will be introduced in Gemini. The project could cost hundreds of millions of dollars, while GPT-4 cost more than $100 million, [according to Altman](https://www.wired.com/story/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over/).
3. 26 Jun, [VentureBeat, Databricks is acquiring MosaicML](https://venturebeat.com/data-infrastructure/databricks-is-acquiring-mosaicml-for-a-jaw-dropping-1-3-billion/) for a jaw-dropping $1.3 billion. The news was also confirmed by both Databricks and MosaicLM, an AI start-up established only one and a half years. MosaicLM believes that every organization should be able to benefit from the AI revolution with more control over how their data is used. MosaicLM has its own open-source [MPT serious LLMs](https://github.com/mosaicml/llm-foundry).
4. 27 Jun, Microsoft [published a paper](https://arxiv.org/pdf/2306.14824.pdf): “KOSMOS-2: Grounding Multimodal Large Language Models to the World”. KOSMOS-2 is a multimodal LLM, enabling new capabilities of perceiving object descriptions and grounding text to the visual world. Researchers also created a large-scale dataset of grounded image-text pairs to train the model. The research lays out the foundation for the development of Embodiment AI.
5. 27 Jun, [Nvidia](https://blogs.nvidia.com/blog/2023/06/27/generative-ai-debut-mlperf/),  H100 GPUs set new records on all eight tests in the latest MLPerf training benchmarks released today, excelling on a new MLPerf test for generative AI. On a commercially available cluster of 3,584 H100 GPUs co-developed by startup Inflection AI and operated by CoreWeave, a cloud service provider specializing in GPU-accelerated workloads, the system completed the massive GPT-3-based training benchmark in less than eleven minutes.
6. 28 Jun, [Meta published a paper](https://arxiv.org/pdf/2306.15595.pdf): “Extending Context Window of Large Language Models via Positional Interpolation”. Researchers present Position Interpolation (PI) that extends the context window sizes of RoPE-based pretrained LLMs such as LLaMA models to up to 32768 with minimal fine-tuning (within 1000 steps), while demonstrating strong empirical results on various tasks that require long context, including passkey retrieval, language modeling, and long document summarization from LLaMA 7B to 65B.
7. 29 Jun, [Oracle CEO said](https://finance.yahoo.com/news/oracle-spending-billions-nvidia-chips-224222975.html?guccounter=1) the company is spending "billions" of dollars on chips from Nvidia Corp as it expands a cloud computing service targeting a new wave of artificial intelligence (AI) companies, also including investment on CPUs.
8. 29 Jun, [Inflection.ai, Microsoft-backed start-up, has raised $1.3 billion](https://www.reuters.com/technology/inflection-ai-raises-13-bln-funding-microsoft-others-2023-06-29/) new funding. "We'll be building a cluster of around 22,000 H100s. This is approximately three times more compute than what was used to train all of GPT4. Speed and scale are what's going to really enable us to build a differentiated product," Suleyman said at Collision Conference on Thursday.
9. 2nd July, [OpenChat](https://github.com/imoneoi/openchat), based on LLaMA-13B, ranked #1 open source LLM on [AlpacaEval leaderboard](https://tatsu-lab.github.io/alpaca_eval/). OpenChat is finetuned with 8xA100 80GB GPUs.


**25 June 2023**
1. GitHub CEO [Dohmke says Copilot](https://www.freethink.com/robots-ai/github-copilot#:~:text=GitHub%20CEO%20says%20Copilot%20will%20write%2080%25%20of%20code%20%E2%80%9Csooner,the%20future%20of%20innovation%20itself.&text=Over%20the%20last%20fifteen%20years,of%20the%20world%20of%20coding.) will write 80% of code “sooner than later”, and that doesn’t mean the developer is going to replace. He also said that Copilot brings the fun back, it brings the creativity back, it brings the flow back.
2. 20th June, Microsoft [published a paper](https://arxiv.org/pdf/2306.11644.pdf) “Textbooks Are All You Need”. Researchers trained a transformer-based model phi-1 with 1.3B parameters trained for 4 days on 8 A100 GPUs, using a selection of textbook quality data from the Web(6B tokens). Phi-1 attains pass@1 accuracy 50.6% on HumanEval and 55.5% on MBPP.
3. 20th June, UC Berkeley researcher announced [vLLM](https://vllm.ai/), an easy, fast and cheap LLM. vLLM equipped with PagedAttention redefines the new state of the art in LLM serving: it delivers up to 24x higher throughput than HuggingFace Transformers, without requiring any model architecture changes. ([Github](https://github.com/vllm-project/vllm))
4. 21st June, [GPT-Engineer is launched on GitHub](https://github.com/AntonOsika/gpt-engineer). GPT Engineer is made to be easy to adapt, extend, and make your agent learn how you want your code to look. It generates an entire codebase based on a prompt. It gains over 30K stars after 4 days.
5. 21st June, George Hotz in [a video said](https://www.latent.space/p/geohot#details) that “so GPT-4 is 220 billion in each head, and then it's an eight-way mixture model. So mixture models are what you do when you're out of ideas. So, you know, it's a mixture model. They just train the same model eight times, and then they have some little trick. They actually do 16 inferences, but no, it's not like- [00:43:45]”
6. 21st June, CNBC, [Google accuses Microsoft](https://www.cnbc.com/2023/06/21/google-accuses-microsoft-of-anticompetitive-practices-in-azure-cloud.html) of using stringent licensing terms to exert monopolistic control over the cloud market.
7. 21st June, [CVPR announced best paper awards](https://www.prnewswire.com/news-releases/cvpr-2023-best-paper-award-winners-announced-301857429.html), best papers: “[Visual Programming: Compositional visual reasoning without training](https://c212.net/c/link/?t=0&l=en&o=3900096-1&h=85460982&u=https%3A%2F%2Farxiv.org%2Fabs%2F2211.11559&a=Visual+Programming%3A+Compositional+visual+reasoning+without+training)”, and “[Planning-oriented Autonomous Driving](https://c212.net/c/link/?t=0&l=en&o=3900096-1&h=2174741114&u=https%3A%2F%2Farxiv.org%2Fabs%2F2212.10156&a=Planning-oriented+Autonomous+Driving)”. Best student paper: “ [3D Registration with Maximal Cliques](https://c212.net/c/link/?t=0&l=en&o=3900096-1&h=152672617&u=https%3A%2F%2Farxiv.org%2Fabs%2F2305.10854&a=3D+Registration+with+Maximal+Cliques)”
8. 22nd June, researchers from MIT and Microsoft [published a paper](https://arxiv.org/pdf/2306.09896.pdf) “Demystifying GPT self-Repair for Code Generation”. They found that “the effectiveness of self-repair is only seen in GPT-4”.
9. 22nd June, LMSYS updated the [leaderboard](https://lmsys.org/blog/2023-06-22-leaderboard/). GPT-4, GPT-3.5-Turbo and Claude-v1 are the top three on the list. The top OSS models are Vicuna-33B, WizardLM-33B, and Guanaco-33B. Falcon-40B  is ranked far below in the list, even below Vicuna-7B model.
10. 22nd June, Stability.ai launched [SDXL 0.9](https://stability.ai/blog/sdxl-09-stable-diffusion), a leap forward in AI image generation. The 0.9 version is the most advanced development in the Stable Diffusion text-to-image suite of models, and can produce massively improved image and composition detail over its predecessor.
11. 22nd June, According to CNBC, [AWS is investing $100 million](https://www.cnbc.com/2023/06/22/aws-invests-100-million-in-generative-ai-as-it-sees-a-long-race-ahead.html) in generative A.I. center in race to keep up with Microsoft and Google.
12. 22nd June,  [ MosaicML released MPT-30B](https://thenewstack.io/mosaicml-launches-30b-model-takes-on-llama-falcon-and-gpt/), ranked the same as Vicuan-13B. The company claims that it surpasses OpenAI’s GPT-3 in quality, despite having about 1/6th the number of parameters (GPT-3 has 175 billion). “This means MPT-30B is easier to run on local hardware and much cheaper to deploy for inference”
13. 22nd June, researchers from MIT and Stanford [published a paper](https://arxiv.org/pdf/2306.12672.pdf) “From Word Models to World Models”. The paper proposed rational meaning construction, a computational framework for language-informed thinking that combines neural models of language with probabilistic models for rational inference.
14. 23rd June, [A team of researchers](https://nbcmontana.com/news/local/um-um-western-researchers-find-openais-gpt-4-outperforms-humans-in-creativity-tests), including professors from the University of Montana and UM Western, have found that OpenAI's GPT-4 scored in the top 1% on the Torrance Tests of Creative Thinking (TTCT), matching or outperforming humans in the creative abilities of fluency, flexibility, and originality.
15. 23rd June, [Microsoft says](https://www.independent.co.uk/tech/quantum-computing-microsoft-supercomputer-ibm-b2362174.html) it has announced plans to build a quantum supercomputer after researchers said the next-generation machines will be able to outperform standard computers within the next two years.


**18 June 2023**
1.	Andrew Ng and Geoff Hinton had an [insightful conversation](https://www.linkedin.com/posts/andrewyng_had-an-insightful-conversation-with-geoff-activity-7073688821803978752-DO9h/?trk=public_profile_share_view). They want to share (i) It's important that AI scientists reach consensus on risks-similar to climate scientists, who have rough consensus on climate change-to shape good policy.
(ii) Do AI models understand the world? We think they do. If we list out and develop a shared view on key technical questions like this, it will help move us toward consensus on risks.
2.	On 12 June 2017, Google published its outstanding paper: “[Attention is All You Need](https://arxiv.org/abs/1706.03762)” which introduced the transformer structure – an essential element widely used in nearly all large deep learning models, both in NLP and Computer Vision. The paper has been cited over 75K, and of eight authors, only one still working in Google.
3.	A new LLM evaluation [leaderboard](https://declare-lab.net/instruct-eval/) is released by researchers from UTD Singapore. The proposed model evaluated three features of LLMs: Problem-Solving, Writing, and Alignment (Harmless, Honesty and Helpfulness)
4.	On 13th June, [MetaAI announced I-JEPA](https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa/), the first AI model based on Yann LeCun’s vision for more human-like AI, which is to create machines that can learn internal models of how the world works so that they can learn much more quickly, plan how to accomplish complex tasks, and readily adapt to unfamiliar situations.
5.	On 14th June, [OpenAI released new GPT-4 and GPT-3.5 Turbo](https://twitter.com/OfficialLoganK/status/1668668826047721494) models with 1) function calling in the API (plugins); 2) 16K context 3.5 Turbo model available to everyone; 3) 75% price reduction on v2 embedding models.
6.	McKinsey released “[The economic potential of generative AI: The next productivity frontier](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier#business-value)”. 1) Generative AI could add $2.6 to $4.4 Trillion in value to the global ecomony; 2) 75% of the value falls in: Customer operations, marketing and sales, software engineering and R&D; 3) Generative AI will have impact across all industry sectors; 4) 50% today’s work activities could be automated between 2030 and 2060; 5) Generative AI is just beginning.
7.	On 14 June, The sequoia published “[The New Language Model Stack](https://www.sequoiacap.com/article/llm-stack-perspective/)” which describes how companies are bringing AI applications to life. 1) Nearly every company in the Sequoia network is building LLMs into their products; 2) The new stack centers on LLM APIs, retrieval, and orchestration, but open source usage is also growing; 3) Companies want to customize LLMs to their unique context; 4) LLMs need to become more trustworthy (output quality, data privacy, security) for full adoption
8.	On 15th June, Princeton Uni published a paper “[Infinite Photorealistic Worlds using Procedural Generation](https://arxiv.org/pdf/2306.09310.pdf)”. It’s worth noting that Infinigen is entirely procedural: every asset, from shape to texture, is generated from scratch via randomized mathematical rules, using no external source and allowing infinite variation and composition.
9.	 On 16th June, Meta published a paper “[Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale](https://research.facebook.com/publications/voicebox-text-guided-multilingual-universal-speech-generation-at-scale/)”. Voicebox is a non-autoregressive flow-matching model trained to infill speech, given audio context and text, trained on over 50K hours of speech that are neither filtered nor enhanced. Voicebox not outperforms the SOT zero-shot TSS model, but also up to 20 times faster
10.	IBM Makes the [Best Quantum Computer Open to Public](https://analyticsindiamag.com/ibm-makes-the-best-quantum-computer-open-to-public/) - IBM in collaboration with UC Berkeley researchers announced a recent breakthrough experiment which indicates that quantum computers will soon surpass classical computers in practical tasks.


**11 June 2023**
1. OpenAI see traffic soar to Billion mark, achieved a total [847 million user access](https://www.digitalinformationworld.com/2023/06/openai-website-sees-traffic-soar-to.html) in March 2023.
2. [Video-LLaMA](https://github.com/damo-nlp-sg/video-llama), a multi-modal framework that empowers Large Language Models (LLMs) with the capability of understanding both visual and auditory content in the video. Video-LLaMA showcases the ability to perceive and comprehend video content, generating meaningful responses that are grounded in the visual and auditory information presented in the videos.
3. [InstructZero](https://arxiv.org/pdf/2306.03082v1.pdf), is an efficient instruction optimization method for black-box large language models by optimizing a low-dimensional soft prompt applied to an open-source LLM to generate the instruction for the black-box LLM.
4. [Git-Theta](https://arxiv.org/pdf/2306.04529v1.pdf) is a Git extension that aims to provide similar functionality for machine learning model checkpoints by efficiently and meaningfully track a model's version history natively through Git. [Link to the project](https://github.com/r-three/git-theta)
5. A github project named [roop](https://github.com/s0md3v/roop) is recently released. It allows anyone to take a video and replace the face in it with a face of your choice. You only need one image of the desired face. No dataset, no training.
6. Facebook published a [paper](https://arxiv.org/pdf/2306.05284v1.pdf) introducing MusicGen, which can generate high-quality samples, while being conditioned on textual description or melodic features, allowing better controls over the generated output. 
7. [SpQR](https://github.com/vahe1994/spqr)- Sparse-Quantized Representation, is a new compressed format and quantization technique which enables for the first time near-lossless compression of LLMs across model scales, while reaching similar compression levels to previous methods. Require GPU VRAM > 32GB.
8. [MAN](https://arxiv.org/pdf/2306.05399v1.pdf) - Matting Anything Model, can estimate the alpha matte of any target instance with user prompts as boxes, points, or text descriptions for interactive use by incorporating [SAM](https://segment-anything.com/). It further reaches comparable performance to the specialized matting models on multiple benchmarks, and shows superior generalization ability with fewer parameters as a unified image matting model.
9. [Video-ChatGPT](https://arxiv.org/pdf/2306.05424v1.pdf), is a multimodal model that merges a video-adapted visual encoder with a LLM. The model is capable of understanding and generating human-like conversations about videos. [Try it here](https://www.ival-mbzuai.com/video-chatgpt).
10. DeepMind publish a [paper in Nature](https://www.nature.com/articles/s41586-023-06004-9): Faster sorting algorithms discovered using deep reinforcement learning. Researchers trained a new deep reinforcement learning agent, AlphaDev, to formulate a task of finding a better sorting routine at assembly-language level as a single-player game.
11. [Magic](https://magic.dev/), an AI startup company, announced [LTM-1](https://twitter.com/magicailabs/status/1666116935904292869), a prototype of a neural network architecture designed for giant context windows, can handle prompt with 5,000,000 tokens, much larger than GPT-4's 32k tokens.
12. Huggingface released [StarCode+](https://huggingface.co/bigcode/starcoderplus) - is a fine-tuned version of [StarCoderBase](https://huggingface.co/bigcode/starcoderbase) on 600B tokens from the English web dataset [RedefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb) combined with [StarCoderData](https://huggingface.co/datasets/bigcode/starcoderdata) from [The Stack (v1.2)](https://huggingface.co/datasets/bigcode/the-stack) and a Wikipedia dataset. It's trained on 512 Tesla A100 GPUs for 14 days.
13. RedPajama released [SlimPajama](https://www.cerebras.net/blog/slimpajama-a-627b-token-cleaned-and-deduplicated-version-of-redpajama) - the largest extensively deduplicated, multi-corpora, open-source dataset for training large language models. [Github link](https://github.com/Cerebras/modelzoo/tree/main/modelzoo/transformers/data_processing/slimpajama)


**4 June 2023**
1.	Google, Princeton, and Stanford published a [paper](https://arxiv.org/pdf/2305.17126.pdf) “Large Language Models as Tool Makers”. The paper proposed a closed-loop framework referred to as LATMs, which can create their own reusable tools for problem-solving. The project uses GPT-3.5 as tool user, and GPT-4 as tool maker to reduce inference costs.
2.	Nvidia announced [DGX GH200](https://nvidianews.nvidia.com/news/nvidia-announces-dgx-gh200-ai-supercomputer), a supercomputer that is 10 times faster than the current fastest computer in the world. The computer will be used for generative AI language applications. Watch [this](https://www.nvidia.com/en-us/events/computex/) from 60mins for about 1 min. Google, Microsoft, and Meta will be its first users.
3.	Nvidia’s [Neuralangelo project](https://blogs.nvidia.com/blog/2023/06/01/neuralangelo-ai-research-3d-reconstruction/) can now turn 2D video clips into 3D structures and scenes. It literally generates detailed replicas of buildings, sculptures, and real objects from video clips taken on a mobile or camera.
4.	[Statement on AI Risk](https://www.safe.ai/statement-on-ai-risk) has been circulated and signed by a lot. “Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war”
5.	OpenAI publishes a research [paper](https://arxiv.org/abs/2305.20050), “let’s verify step by step”, by using this process supervision approach, the process-supervised model solves 78% of the problem from the MATH test set. It also aims at attack the Hallucination issues of LLMs.
6.	[GPT4Tools](https://github.com/StevenGrove/GPT4Tools) – an open-source tool based on Vicuan (LLaMA), and aims to efficiently enable LLMs to decide, control and utilizing different visual foundation models, allowing users to interact with images during a conversation.
7.	Google, OpenAI, Anthropic, etc published a [paper](https://arxiv.org/pdf/2305.15324.pdf) “Model evaluation for extreme risks”. An evaluation model is created to evaluate extreme risks by looking at dangerous capabilities and alignment as input and to ensure responsible training, responsible deployment, transparency and appropriate security.


**28 May 2023**
1.	Meta published a [paper](https://arxiv.org/abs/2305.11206): LIMA Less is more for Alignment. Use carefully cured 1000 high-quality prompts, LIMA beats Google’s Bard, and GPT-3.5, and just below GPT-4.
2.	On 22nd May, Meta released [Massively Multilingual Speech AI](https://about.fb.com/news/2023/05/ai-massively-multilingual-speech-technology/), a single multilingual speech recognition model which can process more than 1000 languages, compared with the previous 100 languages only.
3.	0n 23rd May, Adobe Photoshop adds [Native AI](https://venturebeat.com/ai/adobe-integrates-generative-ai-directly-into-photoshop-with-new-firefly-capabilities/), unlike other open source software, it’s a commercially safe model, using high-quality images, and without copyright issues.
4.	On 23rd May, Microsoft released [Windows Copilot](https://blogs.windows.com/windowsdeveloper/2023/05/23/bringing-the-power-of-ai-to-windows-11-unlocking-a-new-era-of-productivity-for-customers-and-developers-with-windows-copilot-and-dev-home/) to Windows 11, it also released a list of other plugins that will greatly improve the productivity of developers and Windows users. Also, Bing is powered by GPT-4 now, but with only 5 QA each month only. Microsoft also announced [Data Fabric](https://learn.microsoft.com/en-us/fabric/get-started/microsoft-fabric-overview), an all-in-one analytics solution that covers everything from data movement to data science, Real-Time Analytics, and business intelligence + services, including data lake, data engineering, and data integration, all in one place.
5.	An interesting [feature of Microsoft 365 Copilot](https://www.youtube.com/watch?v=qMGLU-chnLk) for drafting legal contracts during Microsoft Build.
6.	On 23rd May, Google Bard  Image generation go online. Eg, ask bard “show me some fashion hair styles in Australia”. It will show you some hairstyles.
7.	Two more models based on LLAMA: [airoboros](https://www.reddit.com/r/LocalLLaMA/comments/13o6kp8/airoboros13b_98_against_gpt35/) and [Guanaco](https://www.reddit.com/r/LocalLLaMA/comments/13rthln/guanaco_7b_13b_33b_and_65b_models_by_tim_dettmers/). Both are close to GPT-3.5 performance, especially the latter, which is based on [QLora](https://arxiv.org/pdf/2305.14314.pdf).
8.	JPMorgan is developing its [IndexGPT](https://www.cnbc.com/2023/05/25/jpmorgan-develops-ai-investment-advisor.html) to select investments for customers.
9.	[Spellbook](https://www.spellbook.legal/) uses GPT-4 and other large language models to review and suggest terms for users’ contracts, right in Microsoft Word.
10.	On 25th May, [TII](https://www.tii.ae/news/uaes-technology-innovation-institute-launches-open-source-falcon-40b-large-language-model) released Falcon 40B and temporarily ranked #1 on [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard). TTI announced it’s an open-source model, but maybe not.
11.	On 27th May, [a lawyer used ChatGPT](https://www.theverge.com/2023/5/27/23739913/chatgpt-ai-lawsuit-avianca-airlines-chatbot-research) to prepare a case in USA and now has to answer for its bogus citations. At least six cases were just made up by ChatGPT. [The fake cases source? ChatGPT](https://edition.cnn.com/2023/05/27/business/chat-gpt-avianca-mata-lawyers/index.html).
12.	Nvidia released GPU-4 Powered [Voyager](https://arxiv.org/abs/2305.16291), a lifeling learning agent in Minecraft that continuously explores the worlds, acquires diverse skills, and makes novel discuveries without human intervention.


**22 May 2023**
1.	On 13 May, Sam Altman announced on his [Twitter](https://twitter.com/sama/status/1657143368198279168) that “all ChatGPT Plus users getting browsing and plugins over the next week”. The time AI can use tools is coming. A new web-browsing feature is set to allow ChatGPT-Plus users to access real-time information. They will also get access to more than 70 plug-ins on sites including Expedia and Instacart (https://www.businessinsider.com/chatgpt-openai-web-browsing-plug-change-how-we-use-internet-2023-5).
2.	LangGPT — [Empowering everyone to become a prompt expert!](https://community.openai.com/t/langgpt-empowering-everyone-to-become-a-prompt-expert/207880) LangGPT addresses how to write high-quality prompts, which is becoming more akin to programming in the AI ear. The project link is [here](https://github.com/yzfly/LangGPT). 
3.	On 17th May, [Google announced](https://blog.google/technology/developers/google-colab-ai-coding-features/) AI-powered features will add to Colab, and free of charge. The features include code completions, natural language to code generation and even a code-assisting chatbot.
4.	On 18th May, OpenAI [announced ChatGPT app for iOS](https://openai.com/blog/introducing-the-chatgpt-app-for-ios). The ChatGPT app is free to use and syncs users history across devices. It also integrates [Whisper](https://openai.com/research/whisper), an open-source speech-recognition system, enabling voice input. [ChatGPT Plus subscribers](https://openai.com/blog/chatgpt-plus) get exclusive access to [GPT-4’s capabilities](https://openai.com/product/gpt-4), early access to features and faster response times.
5.	OpenAI CEO [calls on government to regulate AI](https://www.msn.com/en-us/news/technology/openai-ceo-calls-on-government-to-regulate-ai/ar-AA1bgSwd) - OpenAI CEO Sam Altman testified before the Senate Judiciary Committee on Tuesday, calling on Congress to pass legislation to regulate AI.
6.	[Drag your GAN](https://vcai.mpi-inf.mpg.de/projects/DragGAN/) – a technology allow one to "drag" any points of the image to precisely reach target points in a user-interactive manner.


**15 May 2023**
1.	[Google.io conference](https://developers.googleblog.com/2023/05/io23-developer-keynote-recap.html) – 1) Introduced PaLM v2 which support Google’s Bard, improved programming coding and dialog quality of Bard, support over 100 language translation, image <-> text generation/analysis, and more; 2) Google search supercharged with AGI, multi-round QA allows following-up question; 3) improved Gmail and Google photos features and others
2.	Anthropic’s [Claude](https://twitter.com/AnthropicAI/status/1656700154190389248?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Etweet) model can process 100K tokens now, more than 3X bigger than GPT-4’s 32K tokens.
3.	Microsoft [announced](https://www.microsoft.com/en-us/microsoft-365/blog/2023/05/09/introducing-the-microsoft-365-copilot-early-access-program-and-new-capabilities-in-copilot/) new capabilities in Copilot, including semantic index, copilot in whiteboard makes Teams meetings and brainstorms more creative and effective; integrate DALL.E  into PowerPoint to automatically generate ppt slides.
4.	OpenAI announced [Shape-E](https://github.com/openai/shap-e), a conditional generative model for 3D assets. Type in text prompts into Shape-E, and the model will produce 3D objects that create better more detailed, and accurate objects.
5.	HuggingFace announced [Transformers Agent](https://huggingface.co/docs/transformers/transformers_agents) – the agent provides a natural language API, which can interpret natural language and use a list of curated tools. The agent dramatically simplifies the process of a pre-trained LLM to call tools. A similar function with [LangChain](https://python.langchain.com/en/latest/index.html) – a framework for developing applications powered by LLM.
6.	Meta announced [ImageBind](https://twitter.com/MetaAI/status/1655989274620358656) – an AI model capable of binding data from six modalities at once, including the 3D shape of an image. [ImageBind](https://ai.facebook.com/blog/imagebind-six-modalities-binding-ai/) outperforms prior individually trained models and helps AI by enabling machines to better analyze many different forms of information together.
7.	OpenAI applied GPT-4 to automatically propose [explanations](https://twitter.com/OpenAI/status/1655982364273831936) for GPT-2’S 300K neurons, and found neurons responding to concepts like similes, “things done correctly”, or expressions of certainty. GitHub link.
8.	IBM announced [Dromedary](https://github.com/IBM/Dromedary), another LLM which uses principle-driven, self-alignment to minimize human supervision, and surpasses the performance of ChatGPT and Alpaca. 


**8 May 2023**
1.	A.I. Is Getting Better at Mind-Reading - [In a recent experiment](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41593-023-01304-9&data=05%7C01%7Cd.zhu%40curtin.edu.au%7Cd3b1a33582834f569baf08db4fb7c304%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638191422898365032%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=ffzeFZDazt0JJRlWoFLNQ1hrIm4IkqODfx5sEXwta20%3D&reserved=0), researchers used large language models to translate brain activity into words. Accuracy can now reach about 83% based the authors’ experiments.
2.	Thursday, Microsoft announced [AI powered Bing plugins](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.bing.com%2Fnew%3Fform%3DMY028Z%26OCID%3DMY028Z&data=05%7C01%7Cd.zhu%40curtin.edu.au%7Cd3b1a33582834f569baf08db4fb7c304%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638191422898365032%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=VjfZIdudGT%2BTwTKZwb0KnetYJK6HWEwdkjiabScyvXc%3D&reserved=0), enable Bing to search/generate multimedia content, and an Action feature coming soon.
3.	Google: ["We have no moat, and neither does OpenAI"](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.semianalysis.com%2Fp%2Fgoogle-we-have-no-moat-and-neither&data=05%7C01%7Cd.zhu%40curtin.edu.au%7Cd3b1a33582834f569baf08db4fb7c304%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638191422898365032%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=%2Fw27hisANe4Xi8QJFxVj9dczbkX8VD85S1zUUiUMqjk%3D&reserved=0). It’s reported that Google is considering to follow the trend of open source of LLM, such as LLAMA. Many startups and company released their AI Chat bot simply based on LLAMA.
