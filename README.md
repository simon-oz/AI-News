# AI-News
Welcome to the Weekly-AI-news!
I mainly focuses more on Generative AI, LLMs and the related, so may miss import AI news in other areas.

**08 Oct 2023**
  1.  29 Sep, according to [Futurism](https://futurism.com/sam-altman-replace-normal-people-ai), OpenAI CEO Sam Altman is attracting attention for his use of the term "median human" in discussing artificial general intelligence (AGI). Altman envisions AGI with intelligence equivalent to a "median human co-worker." Critics find this terminology concerning, suggesting it implies replacing normal human jobs with AGI. Altman's previous comments on AGI's ability to perform various tasks further fuel concerns about job displacement. Critics argue that equating AI performance to human intelligence oversimplifies complex aspects of human cognition and raises ethical questions about assigning agency and comprehension to mechanistic models. Despite Altman's ambitions to use AI for societal benefit, his conceptualization of humanity as "median figures" provokes debate and skepticism about the impact of AGI on employment and the human experience.


  2.  29 Sep, Microsoft released its [GPT-4V evaluation report](https://browse.arxiv.org/pdf/2309.17421.pdf) “The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)”. The report focuses on the intriguing tasks that GPT-4V can perform, containing test samples to probe the quality and genericity of GPT-4V’s capabilities, its supported inputs and working modes, and the effective ways to prompt the model. Researchers curate and organize a collection of carefully designed qualitative samples spanning a variety of domains and tasks. Observations from these samples demonstrate that GPT-4V’s unprecedented ability in processing arbitrarily interleaved multimodal inputs and the genericity of its capabilities together make GPT-4V a powerful multimodal generalist system. Furthermore, GPT-4V’s unique capability of understanding visual markers drawn on input images can give rise to new human-computer interaction methods such as visual referring prompting.



  3.  29 Sep, researchers from MIT, Meta AI and CMU published a [paper](https://browse.arxiv.org/pdf/2309.17453.pdf) “Efficient Streaming Language Models with Attention Sinks”. The paper argues that there are two challenges for LLM streaming applications. Firstly, during the decoding stage, caching previous tokens’ Key and Value states (KV) consumes extensive memory. Secondly, popular LLMs cannot generalize to longer texts than the training sequence length. Researchers observe an interesting phenomenon, namely attention sink, that keeping the KV of initial tokens will largely recover the performance of window attention. The paper first demonstrates that the emergence of attention sink is due to the strong attention scores towards initial tokens as a “sink” even if they are not semantically important. Based on the above analysis, researchers introduce StreamingLLM, an efficient framework that enables LLMs trained with a finite length attention window to generalize to infinite sequence length without any fine-tuning. Researchers show that StreamingLLM can enable Llama-2, MPT, Falcon, and Pythia to perform stable and efficient language modeling with up to 4 million tokens and more. In addition, they discover that adding a placeholder token as a dedicated attention sink during pre-training can further improve streaming deployment. In streaming settings, StreamingLLM outperforms the sliding window recomputation baseline by up to 22.2× speedup.



  4.  2 Oct, Statility.AI released [Stable LM 3B](https://stability.ai/blog/stable-lm-3b-sustainable-high-performance-language-models-smart-devices#:~:text=The%20development%20of%20Stable%20LM,costs%20low%20and%20performance%20high.). one of the key advantages of Stable LM 3B is its smaller size and efficiency. Unlike larger ones, these models require fewer resources and come with lower operating costs, making them highly accessible for most users. Not only does this make them more affordable, but it also makes them environmentally friendly, as they consume far less power. But do not let its size fool you; Stable LM 3B is highly competitive - it outperforms the previous state-of-the-art 3B parameter language models and even some of the best open-source language models at the 7B parameter scale.  The development of Stable LM 3B broadens the range of applications that are viable on the edge or on home PCs. This means that individuals and companies can now develop cutting-edge technologies with strong conversational capabilities – like creative writing assistance – while keeping costs low and performance high.



  5.  2 Oct, according [Fortune](https://fortune.com/2023/10/03/microsoft-ceo-satya-nadella-google-antitrust-search-default-chatgpt-market-share/), Microsoft CEO Satya Nadella said Monday that unfair tactics used by Google led to its dominance as a search engine, tactics that in turn have thwarted his company’s rival program, Bing. Nadella testified in a packed Washington, D.C., courtroom as part of the government’s landmark antitrust trial against Google’s parent company, Alphabet. The Justice Department alleges Google has abused the dominance of its ubiquitous search engine to throttle competition and innovation at the expense of consumers, allegations that echo a similar case brought against Microsoft in the late 1990s. Nadella said Google’s dominance was due to agreements that made it the default browser on smartphones and computers. He downplayed the idea that artificial intelligence or more niche search engines like Amazon or social media sites have meaningfully changed the market in which Microsoft competes with Google.



  6.  3 Oct, researchers from MIT published a [paper](https://browse.arxiv.org/pdf/2310.02207.pdf) “Language Models Represent Space and Time”. The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a coherent model of the data generating process—a world model. The research finds evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. Researchers discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, researchers identify individual “space neurons” and “time neurons” that reliably encode spatial and temporal coordinates. Analysis demonstrates that modern LLMs acquire structured knowledge about fundamental dimensions such as space and time, supporting the view that they learn not merely superficial statistics, but literal world models.



  7.  3 Oct, researcher from Center for AI Safety and a list of universities published a [paper](https://browse.arxiv.org/pdf/2310.01405.pdf) “Representation Engineering: A Top-Down Approach to AI Transparency”. In this paper, researchers identify and characterize the emerging area of representation engineering (RepE), an approach to enhancing the transparency of AI systems that draws on insights from cognitive neuroscience. RepE places population level representations, rather than neurons or circuits, at the center of analysis, equipping them with novel methods for monitoring and manipulating high-level cognitive phenomena in deep neural networks (DNNs). Researchers provide baselines and an initial analysis of RepE techniques, showing that they offer simple yet effective solutions for improving the understanding and control of large language models. Researchers showcase how these methods can provide traction on a wide range of safety-relevant problems, including honesty, harmlessness, power seeking, and more, demonstrating the promise of top-down transparency research.



  8.  4 Oct, Anthropic [published a blog](https://www.anthropic.com/index/evaluating-ai-systems) “Challenges in evaluating AI systems”. The blog states that many of today’s existing evaluation suites are limited in their ability to serve as accurate indicators of model capabilities or safety. The blog lists challenges encountered by the company as 1) Multiple choice evaluations, 2) Third-party evaluation frameworks like BIG-bench and HELM, 3) Using crowdworkers to measure how helpful or harmful our models are, 4)  Using domain experts to red team for national security-relevant threats, 5) Using generative AI to develop evaluations for generative AI, 6) Working with a non-profit organization to audit our models for dangerous capabilities. Two main takeaways are: robust evaluations are extremely difficult to develop and implement, and effective AI governance depends on our ability to meaningfully evaluate AI systems.


  9.  4 Oct, according to [TheInformation](https://twitter.com/theinformation/status/1709333094195458314), OpenAI rival Anthropic wants to raise $2 billion from Google and other investors at a valuation of $20 billion or more. The 2-year-old startup, which sells Claude, a chatbot that competes with OpenAI’s ChatGPT, wants a valuation between $20 billion to $30 billion including the new investment, according to one of those people. That would quintuple the valuation of the company since March, when investors put a $4 billion price tag on the firm, and make its shares far pricier than those of OpenAI in terms of its valuation multiple on revenue.



  10.  4 Oct, according to [Yahoo!Finance](https://finance.yahoo.com/news/databricks-valuation-skyrockets-43-billion-161255240.html?guccounter=1), with the initial public offering (IPO) market heating up, data analytics platform Databricks Inc. has been leveraging the renewed interest of venture capitalists to raise funds. As one of the most promising unicorns backed by chipmaker Nvidia Corp., the company raised over $500 million in capital last month, bringing its valuation to $43 billion. The wobbly tech markets failed to deter the data analytics firm, as Databricks has been cashing in on the rising popularity of artificial intelligence (AI). "The commitment from long-term focused strategic and financial partners reflects Databricks' continued momentum, the rapid customer adoption of the Databricks Lakehouse, and the success customers are seeing from moving to a unified data and AI platform," Databricks Co-Founder and CEO Ali Ghodsi stated in a press release.



  11.  5 Oct, researchers from Microsoft and UWM published a [paper](https://browse.arxiv.org/pdf/2310.03744.pdf) “Improved Baselines with Visual Instruction Tuning”. The research shows that the fully-connected vision-language cross-modal connector in LLaVA is surprisingly powerful and data-efficient. With simple modifications to LLaVA, namely, using CLIP-ViT-L-336px with an MLP projection and adding academic-task-oriented VQA data with simple response formatting prompts, researchers establish stronger baselines that achieve state-of-the-art across 11 benchmarks. The final 13B checkpoint uses merely 1.2M publicly available data, and finishes full training in ∼1 day on a single 8-A100 node.



**1 Oct 2023**


1.	25 Sep, OpenAI enhanced the capability of GPT-4. According to a [blog of OpenAI](https://openai.com/blog/chatgpt-can-now-see-hear-and-speak), they are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you’re talking about.

2.	25 Sep, [according to Reuters](https://www.reuters.com/markets/deals/amazon-steps-up-ai-race-with-up-4-billion-deal-invest-anthropic-2023-09-25/), Amazon said it will invest up to $4 billion in cash in the high-profile startup Anthropic, n its effort to compete with growing cloud rivals on artificial intelligence. Amazon's employees and cloud customers will gain early access to technology from Anthropic as part of the deal, which they can infuse into their businesses. The San Francisco-based startup also committed to rely primarily on Amazon's cloud services, including training its future AI models on large quantities of proprietary chips it would buy from the online retailing and computing giant.

3.	25 Sep, [PyTorch published a blog](https://pytorch.org/blog/inside-the-matrix/) introducing how they use 3D to visualize matrix multiplication expressions, attention heads with real weights, and more. The visualizing matrix multiplications (matmuls, or mm) helps build intuition and spark ideas with less cognitive overhead than the usual squares-on-paper idioms, especially (though not only) for visual/spatial thinkers. mm is fully interactive, [runs in the browser](https://bhosmer.github.io/mm/) or [notebook](https://colab.research.google.com/drive/1wZIoU20eRWKtRNCW7e5Iugm3MhfaE1f7) iframes and keeps its complete state in the URL, so links are shareable sessions (the screenshots and videos in this note all have links that open the visualizations in the tool). This [reference guide](https://bhosmer.github.io/mm/ref.html) describes all of the available functionality.

4.	25 Sep, [Meta published a paper](https://arxiv.org/pdf/2309.14402.pdf) “Physics of Language Models: Part 3.2, Knowledge Manipulation”. This paper explores a language model’s ability to manipulate its stored knowledge during inference. Researchers focus on four manipulation types: retrieval (e.g., “What is person A’s attribute X ”), classification (e.g., “Is A’s attribute X even or odd?”), comparison (e.g., “Is A greater than B in attribute X?”) and inverse search (e.g., “Which person’s attribute X equals T?”). They observe that pre-trained language models like GPT2/3/4 excel in knowledge retrieval but struggle with simple classification or comparison tasks unless Chain of Thoughts (CoTs) are employed during both training and inference. They also perform poorly in inverse knowledge search, irrespective of the prompts.

5.	25 Sep, [according to venturebeat](https://venturebeat.com/ai/google-bard-fails-to-deliver-on-its-promise-even-after-latest-updates/), Google recently revamped its AI chatbot Bard, integrating it into popular products like Gmail, Docs, Drive, Maps, and YouTube. This move positions Bard to compete with ChatGPT, the market leader from OpenAI and Microsoft. The introduction of Bard Extensions, theoretically allowing the AI to pull live personalized data from Google services, seems promising. However, in practical use, Bard falls short of expectations. Despite its access to Google's vast ecosystem, it often produces inaccurate or nonsensical responses and lacks the creativity of OpenAI's GPT-4. The underlying issue lies in Bard's model, PaLM 2, trained on 340 billion parameters, significantly fewer than the rumored 1.8 trillion parameters of GPT-4. This disparity implies that GPT-4 may have a broader knowledge base, potentially leading to more relevant and interesting outputs.

6.	26 Sep, [Mckinsey announced](https://www.mckinsey.com/about-us/new-at-mckinsey-blog/mckinsey-launches-an-open-source-ecosystem) the launch of a McKinsey open-source ecosystem that will host products from across the firm, including some of our leading-edge technologies and IP in AI including generative AI, digital, and cloud.  The first major release in our collection is Vizro, a new component from our QuantumBlack Horizon suite, which helps users visualize data from their AI models. In addition to Vizro, the new ecosystem will host CausalNex, a tool for building cause-and-effect models that has been available to the public since 2020 through QuantumBlack Labs’ GitHub organization. Vizro, the newest Horizon component, creates high-quality visualizations that allows users to better explore and analyze data from their models. In a matter of hours rather than weeks, teams can collaborate to define insights and present them to clients in live workshops or demos.

7.	26 Sep, researchers from UC Berkley, NYU [published a paper](https://arxiv.org/pdf/2309.10313.pdf) “Investigating the Catastrophic Forgetting in Multimodal Large Language Models”. They find that catastrophic forgetting, a notorious phenomenon where the finetuned model fails to retain similar performance compared to the pre-trained model, still remains an inherent problem in multimodal LLMs (MLLM). They introduce EMT: Evaluating MulTimodality for evaluating the catastrophic forgetting in MLLMs, by treating each MLLM as an image classifier. Experimental results suggest that early-stage fine-tuning on an image dataset improves performance across other image datasets, by enhancing the alignment of text and visual features. However, as fine-tuning proceeds, the MLLMs begin to hallucinate, resulting in a significant loss of generalizability, even when the image encoder remains frozen. The results suggest that MLLMs have yet to demonstrate performance on par with their vision models on standard image classification tasks and the current MLLM fine-tuning procedure still has room for improvement.

8.	26 Sep, researcher from Oxford, Cambridge and Yule University [published a paper](https://arxiv.org/pdf/2309.15840v1.pdf) “How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions”. “Lie” of an LLM is defined as outputting false statements despite “knowing” the truth in a demonstrable sense. LLMs might “lie”, for example, when instructed to output misinformation. Here, they develop a simple lie detector that requires neither access to the LLM’s activations (black-box) nor ground-truth knowledge of the fact in question. The detector works by asking a predefined set of unrelated follow-up questions after a suspected lie, and feeding the LLM’s yes/no answers into a logistic regression classifier. Despite its simplicity, this lie detector is highly accurate and surprisingly general. Experimental results indicate that LLMs have distinctive lierelated behavioural patterns, consistent across architectures and contexts, which could enable general-purpose lie detection.

9.	27 Sep, Meta [published a blog](https://ai.meta.com/blog/llama-2-updates-connect-2023/) “The Llama Ecosystem: Past, Present, and Future”. The LLaMA community has seen a lot of momentum and innovation, with more than 30 million downloads of Llama-based models through Hugging Face and over 10 million of these in the last 30 days alone. Much like PyTorch, Llama has evolved into a platform for the world to build on, and we couldn’t be more excited. The impact to date includes cloud usage, innovators (Scala AI, Replicate, Anyscale), crowd sourced optimization (fined tuned over 7,000 derivatives on Huggingface only !), hardware support (AMD, Intel, Nvidia, and Google all have boosted the performance of Llama2 via hardware/software optimizations). Meta believes deeply in the power of the open source community. Meta also believes that state-of-the-art AI technology is safer and better aligned when it’s open and accessible to everyone. The blog also indicate three future directions: multimodal, safety and responsibility and a focus on community.

10.	27 Sep, Meta [published a paper](https://ai.meta.com/research/publications/effective-long-context-scaling-of-foundation-models/) “Effective Long-Context Scaling of Foundation Models”, a series of long-context LLMs that support effective context windows of up to 32,768 tokens. The model series are built through continual pretraining from LLAMA 2 with longer training sequences and on a dataset where long texts are upsampled. The models achieve consistent improvements on most regular tasks and significant improvements on long-context tasks over LLAMA 2. Notably, with a cost-effective instruction tuning procedure that does not require human-annotated long instruction data, the 70B variant can already surpass gpt-3.5-turbo-16k’s overall performance on a suite of long-context tasks. Ablation experiments suggest that having abundant long texts in the pretrain dataset is not the key to achieving strong performance, and the empirically verify that long context continual pretraining is more efficient and similarly effective compared to pretraining from scratch with long sequences. Specifically, researchers take the RLHF dataset used in LLAMA 2 CHAT and augment it with synthetic self-instruct (Wang et al., 2022) long data generated by LLAMA 2 CHAT itself, in the hope that the model can learn a diverse set of skills through a large amount of RLHF data and transfer that knowledge to long-context scenarios via self-instruct data.

11.	27 Sep, Meta [published a paper](https://arxiv.org/pdf/2309.16058.pdf) "AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model". AnyMAL - Any-Modality Augmented Language Model, a unified model that reasons over diverse input modality signals (i.e. text, image, video, audio, IMU motion sensor), and generates textual responses. AnyMAL inherits the powerful text-based reasoning abilities of the state-of-the-art LLMs including LLaMA-2 (70B), and converts modality-specific signals to the joint textual space through a pre-trained aligner module. To further strengthen the multimodal LLM’s capabilities, researchers fine-tune the model with a multimodal instruction set manually collected to cover diverse topics and tasks beyond simple QAs.

12.	27 Sep, Nature [published a paper](https://www.nature.com/articles/d41586-023-02999-3) “AI tools as science policy advisers? The potential and the pitfalls”. The article suggests that with careful development and management, a new generation of AI-based tools could, in the near future, present an opportunity to drastically improve science advice, making it more agile, rigorous and targeted. But leveraging such tools for good will require science advisers and policy institutions to create guidelines and to carefully consider the design and responsible use of this nascent technology. The paper also discusses two tasks for which generative AI tools hold promise for policy guidance — synthesizing evidence and drafting briefing papers — and highlight areas needing closer attention.

13.	27 Sep, Mistral AI [released Mistral 7B](https://mistral.ai/news/announcing-mistral-7b/), the most powerful language model for its size to date. Mistral outperforms Llama2 13B on all benchmarks, outperforms Llama 1 34B on many benchmarks, approaches CodeLlama 7B performance on code, while remaining good at English tasks, provide fast inference, and can handle longer sequences at smaller cost.

14.	28 Sep, a group of researchers from USA [published a paper](https://arxiv.org/abs/2309.16145) “The Confidence-Competence Gap in Large Language Models: A Cognitive Study”. Researchers exploit these models with diverse sets of questionnaires and real-world scenarios and extract how LLMs exhibit confidence in their responses. The findings reveal intriguing instances where models demonstrate high confidence even when they answer incorrectly. This is reminiscent of the Dunning-Kruger effect observed in human psychology. In contrast, there are cases where models exhibit low confidence with correct answers revealing potential underestimation biases. The results underscore the need for a deeper understanding of their cognitive processes.

15.	28 Sep, [Meta Connect2023](https://www.metaconnect.com/en/home) was hold at Menlo Park, California, from 27 to 28 Sep 2023. Key things in the meeting include but are not limited to 1) Meta QUEST 3, the headset model with improved passthrough tech, higher resolution displays and better graphics; 2) Emu, a new foundational model for image generation which can be used in Meta apps such as WhatsApp, Messenger, Instagram and Facebook stories; 3) Ray-Ban Meta smart glasses which have two round modules on the side of either eye include a 12-megapixel camera and an LED light that flips on to alert others that you’re recording; 4) Meta AI, which can help plan a trip with friends in a group chat, answer general-knowledge questions, and search the internet across Microsoft’s Bing to provide real-time web results. 


**24 Sep 2023**
1.	Sep, [According to Harvard Business School](https://www.hbs.edu/faculty/Pages/item.aspx?num=64700#:~:text=For%20each%20one%20of%20a%20set%20of%2018,40%25%20higher%20quality%20compared%20to%20a%20control%20group%29.), researchers from Harvard, MIT and other institutes, a large-scale field experiment has been conducted to investigate how human will use AI to accomplish a variety of tasks. The pre-registered experiment involved 758 consultants comprising about 7% of the individual contributor-level consultants at the company. After establishing a performance baseline on a similar task, subjects were randomly assigned to one of three conditions: no AI access, GPT-4 AI access, or GPT-4 AI access with a prompt engineering overview. We suggest that the capabilities of AI create a “jagged technological frontier” where some tasks are easily done by AI, while others, though seemingly similar in difficulty level, are outside the current capability of AI. For each one of a set of 18 realistic consulting tasks within the frontier of AI capabilities, consultants using AI were significantly more productive (they completed 12.2% more tasks on average, and completed tasks 25.1% more quickly), and produced significantly higher quality results (more than 40% higher quality compared to a control group). Consultants across the skills distribution benefited significantly from having AI augmentation, with those below the average performance threshold increasing by 43% and those above increasing by 17% compared to their own scores. For a task selected to be outside the frontier, however, consultants using AI were 19 percentage points less likely to produce correct solutions compared to those without AI. Further, our analysis shows the emergence of two distinctive patterns of successful AI use by humans along a spectrum of human-AI integration. One set of consultants acted as “Centaurs,” like the mythical half-horse/half-human creature, dividing and delegating their solution-creation activities to the AI or to themselves. Another set of consultants acted more like “Cyborgs,” completely integrating their task flow with the AI and continually interacting with the technology. 

2.	18 Sep, [theinformation published an article](https://www.theinformation.com/articles/openai-hustles-to-beat-google-to-launch-multimodal-llm?utm_source=bensbites&utm_medium=referral&utm_campaign=openai-hustles-to-beat-google-to-launch-multimodal-llm) “OpenAI Hustles to Beat Google to Launch ‘Multimodal’ LLM”. With all the reports of Gemini being released soon and potentially better than GPT-4, Open AI is trying to keep its lead intact. The multimodal features will be launched under the name “GPT-vision.” Also, they are training a multimodal LLM from scratch codenamed Gobi. These new “multimodal” models will be able to generate code from website sketches and analyze visual data, among other capabilities. Google is close to releasing its Gemini model, while OpenAI is rushing to add multimodal features to GPT-4. There are concerns around potential misuse, but both companies are taking steps to ensure responsible development. This race parallels big tech platform competitions like iPhone vs Android.

3.	19 Sep, Google published a [paper](https://www.science.org/doi/10.1126/science.adg7492) on Science, “Accurate proteome-wide missense variant effect prediction with AlphaMissense”. According to [Google DeepMind](https://twitter.com/GoogleDeepMind?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1704145467129389178%7Ctwgr%5E1b66b27bb7a7a9342385fa2d6d6cb534ac787560%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fwww.news-medical.net%2Fnews%2F20230920%2FAlphaMissense-revolutionizes-genetic-mutation-analysis-for-disease-prediction.aspx), uncovering the causes of disease is one of the greatest challenges in genetics, to help advance this, they created AlphaMissense: an AI model classifying missense variants – or genetic changes affecting proteins. The model is trained on population frequency data and uses sequence and predicted structural context, all of which contribute to its performance. The authors evaluated the model against related methods using clinical databases not included in the training and demonstrated agreement with multiplexed assays of variant effect.

4.	19 Sep, [Google updated Bard](https://blog.google/products/bard/google-bard-new-features-update-sept-2023/) by adding Bard Extensions in English. With Extensions, Bard can find and show you relevant information from the Google tools you use every day — like Gmail, Docs, Drive, Google Maps, YouTube, and Google Flights and hotels — even when the information you need is across multiple apps and services. One can also use Bard’s “Google it” button to more easily double-check its answers. Other new features include  upload images with Lens, get Search images in responses, and modify Bard’s responses — to more than 40 languages.

5.	20 Sep, according to [TheNextPlatform](https://www.nextplatform.com/2023/09/20/sambanova-tackles-generative-ai-with-new-chip-and-new-approach/), the Global 50,000, national and regional governments, and large academic institutions will take a pre-trained model and tweak and tune it so it can focus on and perform generative tasks upon their internal proprietary data. SambaNova, an AI hardware start-up released SN40L, which is architected specifically to run a modest-sized model on a single device and to have lots of models running side-by-side. With a cluster of eight SN40L sockets, it can handle more than 5 trillion parameters, says Liang, one of the founders of Sambanova. So two clusters of eight machines will give users all the models might need for a Global 2000 enterprise given the logic that SambaNova is using.

6.	20 Sep, [Sequia published an article](https://www.sequoiacap.com/article/generative-ai-act-two/) “Generative AI’s Act Two”. The article argues that Generative AI has had a successful first year, with over $1 billion in revenue from startups alone. Some applications have become household names, such as ChatGPT, Midjourney, and Character. However, many AI companies do not have product-market fit or a sustainable competitive advantage, and the overall ebullience of the AI ecosystem is unsustainable. The market is now entering "Act 2," which will be from the customer-back. Act 2 will solve human problems end-to-end, with applications that are more comprehensive and user-friendly than the first apps out of the gate. The generative AI market map has been updated to reflect the evolution of the market from technology hammer to actual use cases and value, and the increasingly multimodal nature of generative AI applications. A new LLM developer stack has also been included to reflect the compute and tooling vendors that companies are turning to as they build generative AI applications in production. The article acknowledges the challenges facing generative AI, particularly in demonstrating value and retaining users. However, it remains optimistic about the market's potential and emphasizes the importance of patience, judgment, and innovation in overcoming these challenges.

7.	21 Sep, Microsoft announced the release of [Microsoft 365 Copilot](https://adoption.microsoft.com/en-us/copilot/), which combines the power of large language models (LLMs) with organization’s data – all in the flow of work – to turn words into one of the most powerful productivity tools on the planet. It works alongside popular Microsoft 365 Apps such as Word, Excel, PowerPoint, Outlook, Teams, and more. Copilot provides real-time intelligent assistance, enabling users to enhance their creativity, productivity, and skills. For example, users can use Copilot in Teams meetings to summarise key discussion points – including who said what and where people are aligned or disagree – and suggest action items, all in real-time during a meeting.

8.	21 Sep, researchers from Vanderbilt university, New York university and other institutes published a [paper](https://arxiv.org/pdf/2309.12288.pdf) ‘The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”’. They named the phenomenon Reversal Curse, i.e. if a model is trained on a sentence of the form “A is B”, it will not automatically generalize to the reverse direction “B is A”. For instance, if a model is trained on “Olaf Scholz was the ninth Chancellor of Germany”, it will not automatically be able to answer the question, “Who was the ninth Chancellor of Germany?”. Moreover, the likelihood of the correct answer (“Olaf Scholz”) will not be higher than for a random name. The researchers also found that  the Reversal Curse is robust across model sizes and model families and is not alleviated by data augmentation. Models tested include GPT-4, ChatGPT and LLaMA.

9.	21 Sep, [AlpacaEval Leaderboard](https://tatsu-lab.github.io/alpaca_eval/) has updated recently. First-time GPT-4 has been over-performed by a new LLM Xwin-lm 70b v0.1. It achieved a win-rate against Davinci-003 of 95.57%, ranking as TOP-1 on AlpacaEval. It was the FIRST model surpassing GPT-4 on AlpacaEval. Also note its winrate v.s. GPT-4 is 60.61. (Note, our test of Xwin-13b seems not comparable even with LLaMA2 13B  in terms of NER extraction)

10.	21 Sep, according to TheVerge, [OpenAI released DALL-E 3](https://www.theverge.com/2023/9/20/23881241/openai-dalle-third-version-generative-ai), which now lets users use ChatGPT to create prompts and includes more safety options. By using ChatGPT, someone doesn’t have to come up with their own detailed prompt to guide DALL-E 3; they can just ask ChatGPT to come up with a prompt, and the chatbot will write out a paragraph (DALL-E works better with longer sentences) for DALL-E 3 to follow. Other users can still use their own prompts if they have specific ideas for DALL-E.



**17 Sep 2023**
1.	7 Sep, researchers from Humboldt university published [paper](https://arxiv.org/pdf/2309.03876.pdf) “OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs”. With this demonstration, researchers take a different view on biases in instruction-tuning: Rather than aiming to suppress them, they aim to make them explicit and transparent. To this end, the researchers present OpinionGPT, a web demo in which users can ask questions and select all biases they wish to investigate. The demo will answer this question using a model fine-tuned on text representing each of the selected biases, allowing side-by-side comparison. To train the underlying model, they identified 11 different biases (political, geographic, gender, age) and derived an instruction-tuning corpus in which each answer was written by members of one of these demographics. Web application available at https://opiniongpt.informatik.hu-berlin.de. 

2.	8 Sep, [accord to ts2.space](https://ts2.space/en/a-new-approach-to-regulating-ai-the-critical-algorithmic-systems-classification/),  Brookings Institution fellow and AI policy expert Alex Engler puts forward a new idea for regulating artificial intelligence (AI) in the face of an increasingly integrated technology that impacts various systems. Engler’s concept, called the Critical Algorithmic Systems Classification, aims to govern algorithms based on their specific applications and expands the authority of regulatory agencies. This approach grants agencies, such as the Department of Education, the Equal Employment Opportunity Commission, and the Department of Health and Human Services, the power to create rules for “especially impactful algorithms” and issue administrative subpoenas for algorithmic investigations. Unlike a massive overhaul of civil rights laws, which would require significant political support, the Critical Algorithmic Systems Classification offers a focused approach to governing AI’s impact on socioeconomic outcomes and health determinations. Engler’s proposal emphasizes the need to adapt existing regulatory agencies to incorporate AI expertise rather than creating a separate federal AI-focused agency. He highlights the importance of building staffing and technical expertise within these agencies to effectively regulate algorithmic systems.

3.	11 Sep, Google published a [paper](https://arxiv.org/pdf/2309.05858.pdf) “Uncovering mesa-optimization algorithms in Transformers”. The paper hypothesizes that the strong performance of Transformers stems from an architectural bias towards mesa-optimization, a learned process running within the forward pass of a model consisting of the following two steps: (i) the construction of an internal learning objective, and (ii) its corresponding solution found through optimization. Moreover, the paper suggests that the learned forward-pass optimization algorithm can be immediately repurposed to solve supervised few-shot tasks, suggesting that mesa-optimization might underlie the in-context learning capabilities of large language models. Finally, the Google researchers propose a novel self-attention layer, the mesa-layer, that explicitly and efficiently solves optimization problems specified in context. They find that this layer can lead to improved performance in synthetic and preliminary language modeling experiments, adding weight to their hypothesis that mesa-optimization is an important operation hidden within the weights of trained Transformers.

4.	11 Sep, [Nvidia published a blog](https://developer.nvidia.com/blog/leading-mlperf-inference-v3-1-results-gh200-grace-hopper-superchip-debut/) to demonstrate the performance of its newest GH200 server, “Leading MLPerf Inference v3.1 Results with NVIDIA GH200 Grace Hopper Superchip Debut”. In its MLPerf debut, the GH200 Grace Hopper Superchip turned in exceptional performance on all workloads and scenarios in the closed division of the data center category, boosting performance by up to 17% on the NVIDIA single-chip H100 SXM submission. The NVIDIA software stack fully supports the GH200 Grace Hopper Superchip today.

5.	11 Sep, [together.ai published a blog](https://together.ai/blog/medusa) “Medusa: Simple Framework for Accelerating LLM Generation with Multiple Decoding Heads”. Instead of using an additional draft model like speculative decoding, Medusa merely introduces a few additional decoding heads, following the idea of [Stern et al. 2018] with some other ingredients. Despite its simple design, Medusa can improve the generation efficiency of LLMs by about 2x. The implementation is available at [this repo](https://github.com/FasterDecoding/Medusa).

6.	11 Sep, researchers from Microsoft published a [paper](https://arxiv.org/pdf/2309.05689.pdf#:~:text=The%20P%20vs%20NP%20problem,problem%20behind%20the%20P!%3D) “Large Language Model for Science: A Study on P vs. NP”. Researchers use large language models (LLMs) to augment and accelerate research on the P versus NP problem. Specifically, they propose Socratic reasoning, a general framework that promotes in-depth thinking with LLMs for complex problem-solving. Socratic reasoning encourages LLMs to recursively discover, solve, and integrate problems while facilitating self-evaluation and refinement. The pilot study on the P vs. NP problem shows that GPT-4 successfully produces a proof schema and engages in rigorous reasoning throughout 97 dialogue turns, concluding “P ̸= NP”, which is in alignment with ([Xu and Zhou, 2023](https://arxiv.org/pdf/2302.09512.pdf)). The investigation uncovers novel insights within the extensive solution space of LLMs, shedding light on LLM for Science.

7.	11 Sep, according to [BusinessInsider](https://www.businessinsider.com/ai-builds-software-under-7-minutes-less-than-dollar-study-2023-9), Researchers in a new study tasked an AI-powered tech company with developing 70 different programs. They found AI could develop software in under seven minutes for less than $1 in costs, on average. AI bots were assigned roles and were able to talk, make logical decisions, and troubleshoot bugs. Here’s the [paper](https://arxiv.org/pdf/2307.07924v3.pdf) and [project](https://github.com/OpenBMB/ChatDev).

8.	12 Sep, CISA of America released [CISA Open Source Software Security Roadmap](https://www.cisa.gov/sites/default/files/2023-09/CISA-Open-Source-Software-Security-Roadmap-508c%20%281%29.pdf). The report states that The federal government, critical infrastructure, and state, local, tribal, and territorial (SLTT) governments greatly depend upon open source software (OSS). OSS is part of the foundation of software used across critical infrastructure, supporting every single critical infrastructure sector and every National Critical Function: one study found that 96% of studied codebases across various sectors contain open source code, and 76% of code in studied codebases was open source. The proposed roadmap centers on four key goals: 1) establishing CISA’s role in supporting the security of OSS, 2) understanding the prevalence of key open source dependencies, 3) reducing risks to the federal government, and 4) hardening the broader OSS ecosystem.

9.	12 Sep, [SCSP released special edition report](https://scsp222.substack.com/p/scsp-releases-special-edition-report?utm_source=profile&utm_medium=reader2) “Generative AI: The Future of Innovation Power”. The Generative AI moment provides the United States Government with a unique opportunity to lead with conviction as humanity enters a new era. This [Special Edition report](https://www.scsp.ai/wp-content/uploads/2023/09/GenAI-web.pdf) provides a comprehensive national security strategy informed by the generative AI models that enhance all elements of our innovation power.

10.	13 Sep, [a16z published a blog](https://a16z.com/how-are-consumers-using-generative-ai/), “How Are Consumers Using Generative AI?” The blog ranks 50 GenAI products, and finds that 1. Most leading products are built from the “ground up” around generative AI; 2. ChatGPT has a massive lead, for now… 3. LLM assistants (like ChatGPT) are dominant, but companionship and creative tools are on the rise; 4. Early “winners” have emerged, but most product categories are up for grabs; 5. Acquisition for top products is entirely organic—and consumers are willing to pay! 6. Mobile apps are still emerging as a GenAI platform.

11.	13 Sep, researchers from the National University of Singapore published a [paper](https://arxiv.org/pdf/2309.05519.pdf): “NExT-GPT: Any-to-Any Multimodal LLM”. The researchers observed that humans always perceive the world and communicate with people through various modalities, so they developed an any-to-any MM-LLM capable of accepting and delivering content in any modality – NExT-GPT. They connect an LLM with multimodal adaptors and different diffusion decoders, enabling NExT-GPT to perceive inputs and generate outputs in arbitrary combinations of text, images, videos, and audio. Overall, the research showcases the promising possibility of building a unified AI agent capable of modeling universal modalities, paving the way for more human-like AI research in the community.

12.	14 Sep, [according to apnews](https://apnews.com/article/schumer-artificial-intelligence-elon-musk-senate-efcfb1067d68ad2f595db7e92167943c),  The nation’s biggest technology executives on Wednesday loosely endorsed the idea of government regulations for artificial intelligence at an unusual closed-door meeting in the U.S. Senate. But there is little consensus on what regulation would look like, and the political path for legislation is difficult. Senate Majority Leader Chuck Schumer, who organized the private forum on Capitol Hill as part of a push to legislate artificial intelligence, said he asked everyone in the room — including almost two dozen tech executives, advocates and skeptics — whether government should have a role in the oversight of artificial intelligence, and “every single person raised their hands, even though they had diverse views,” he also said  regulation of artificial intelligence will be “one of the most difficult issues we can ever take on,” and he listed some of the reasons why: It’s technically complicated, it keeps changing and it “has such a wide, broad effect across the whole world”. Sarah Myers West, managing director of the nonprofit AI Now Institute, estimated that the combined net worth of the room Wednesday was $550 billion and it was “hard to envision a room like that in any way meaningfully representing the interests of the broader public.” She did not attend. At the same time during the Congress meeting, [ChatGPT was down](https://futurism.com/the-byte/chatgpt-down-sam-altman-washington) for about two hours.

13.	15 Sep, [according to CNBC](https://www.cnbc.com/2023/09/14/oracle-founder-larry-ellison-makes-first-trip-to-microsoft-campus.html), Oracle founder Larry Ellison makes first-ever trip to Microsoft headquarters for cloud announcement. According to the report, Oracle co-founder and technology chief Larry Ellison and Microsoft CEO Satya Nadella spoke at a presentation on Microsoft’s campus to announce an extension of their partnership. Ellison said Oracle hardware is coming to Microsoft’s data centers, enabling organizations that use Microsoft’s Azure cloud to draw on Oracle database services, although the two companies have gone up against each other for over three decades. “Whether it is fine-tuning a model, pre-training a model or meta-prompting a model requires that low latency access to data,” [Nadella said](https://www.crn.com/news/cloud/microsoft-ceo-nadella-calls-joint-oracle-offering-a-profound-moment-for-ai). “And so we’re very excited. I think this is the moment where data and AI coming together to transform businesses and business process – there couldn’t be a more profound timing of these two things.”

14.	15 Sep, [according to MIT Technology Review](https://www.technologyreview.com/2023/09/15/1079624/deepmind-inflection-generative-ai-whats-next-mustafa-suleyman/), DeepMind cofounder Mustafa Suleyman wants to build a chatbot that does a whole lot more than chat. he told the magazine that generative AI is just a phase. What’s next is interactive AI: bots that can carry out tasks you set for them by calling on other software and other people to get stuff done. He also calls for robust regulation—and doesn’t think that’ll be hard to achieve.
    
16.	15 Sep, [according to BusinessInsider](https://www.businessinsider.com/google-ceo-isnt-worried-about-falling-behind-on-ai-2023-9), Google CEO says he isn't worried about catching up to OpenAI after the search engine reportedly declared a 'code red': 'I feel very comfortable about where we are.' Releasing Google's AI products before ChatGPT was launched "wouldn't have worked out as well," he said. Pichai's thoughts on AI come months after Google reportedly declared a "code red" for its search engine, per NYT. 

17.	15 Sep, [according to the-decoder](https://the-decoder.com/google-begins-external-testing-of-its-gpt-4-competitor-gemini/), Google begins external testing of its GPT-4 competitor "Gemini". According to three anonymous sources from The Information, Google has given a small group of selected companies access to a stripped-down chat version of Gemini. The three sources claim to have direct knowledge of the matter. The largest version of Gemini is still being developed internally. Gemini will be offered to businesses via cloud access and integrated into Google's consumer products. Google plans to use Gemini for all of its AI applications, from the Bard chatbot to the new AI features in Workspace. Gemini, according to The Information, is "a set of large language models" that can perform various tasks such as chatbots, text summarization, code, or generating new text. It is unclear whether Gemini will rely on networked expert models, as OpenAI does with its GPT-4 architecture.

18.	16 Sep, researchers from Singapore University of Technology and Design released [TinyLlama](https://github.com/jzhang38/TinyLlama), which aims to pretrain a 1.1B Llama model on 3 trillion tokens. With some proper optimization, we can achieve this within a span of "just" 90 days using 16 A100-40G GPUs.


**11 Sep 2023**
1.	1 Sep, [Google published a paper](https://arxiv.org/pdf/2309.00267.pdf) “RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback”. RLAIF (RL from AI Feedback) is a technique where preferences are labeled by an off-the-shell LLM in lieu of humans. On the task of summarization, human evaluators prefer generations from both RLAIF and RLHF over a baseline supervised fine-tuned model in ∼70% of cases. Furthermore, when asked to rate RLAIF vs. RLHF summaries, humans prefer both at equal rates. These results suggest that RLAIF can yield human-level performance, offering a potential solution to the scalability limitations of RLHF .

2.	1 Sep, [OpenAI published a paper](https://arxiv.org/pdf/2309.00667.pdf) “Taken out of context: On measuring situational awareness in LLMs”. First, A model is situationally aware if it’s aware that it’s a model and can recognize whether it’s currently in testing or deployment. According to researchers, today’s LLMs are tested for safety and alignment before they are deployed. An LLM could exploit situational awareness to achieve a high score on safety tests while taking harmful actions after deployment. This research moves further from an [article published by Nature](https://www.nature.com/articles/d41586-023-02684-5) “If AI becomes conscious: here’s how researchers will know” where scientists believed that Human-like behaviours can make it difficult to judge robots’ true level of engagement.

3.	4 Sep, a group of researchers from 22 universities and security institues publish a [paper](https://arxiv.org/pdf/2307.03718.pdf) "Frontier AI Regulation: Managing Emerging Risks to Public Safety". “frontier AI” models is defined as 'highly capable foundation models that could possess dangerous capabilities sufficient to pose severe risks to public safety.'  The models pose a distinct regulatory challenge: dangerous capabilities can arise unexpectedly; it is difficult to robustly prevent a deployed model from being misused; and, it is difficult to stop a model’s capabilities from proliferating broadly. To address these challenges, at least three building blocks for the regulation of frontier models are needed: (1) standard-setting processes to identify appropriate requirements for frontier AI developers, (2) registration and reporting requirements to provide regulators with visibility into frontier AI development processes, and (3) mechanisms to ensure compliance with safety standards for the development and deployment of frontier AI models. Industry self-regulation is an important first step. However, wider societal discussions and government intervention will be needed to create standards and to ensure compliance with them. Finally, the paper proposes an initial set of safety standards include conductingpre-deployment risk assessments; external scrutiny of model behavior; using risk assessments to inform deployment decisions; and monitoring and responding to new information about model capabilities and uses post-deployment.

4.	4 Sep, [according to Itnews](https://www.itnews.com.au/news/microsoft-had-three-staff-at-australian-data-centre-campus-when-azure-went-out-599849), Microsoft had “insufficient” staff levels at its data centre campus last week when a power sag knocked its chiller plant for two data halls offline, cooking portions of its storage hardware. The company has [released a preliminary post-incident report](https://azure.status.microsoft/en-au/status/history/) (PIR) for the large-scale failure, which saw large enterprise [customers including Bank of Queensland and Jetstar completely lose service](https://www.itnews.com.au/news/bank-of-queensland-jetstar-among-australian-enterprises-impacted-by-azure-outage-599803).

5.	4 Sep, [ColosalAI released its 70B parameter](https://www.hpc-ai.tech/blog/70b-llama2-training) LLaMA2 model. The model training is accelerated by 195% with the best foundation model practice upgraded. Colossal-AI has open-sourced a full-flow solution for LLaMA2 with high scalability. This supports models ranging from 7 to 70 billion parameters, while still maintaining good performance from 8 to 512 GPUs. Users only need to upload relevant data to train personalized private models without code and can deploy the trained models with one click.

6.	6 Sep, [TII announced Falcon 180B](https://falconllm.tii.ae/falcon-180b.html). Falcon 180B is a super-powerful language model with 180 billion parameters, trained on 3.5 trillion tokens. It's currently at the top of the Hugging Face Leaderboard for pre-trained Open Large Language Models and is available for both research and commercial use. This model performs exceptionally well in various tasks like reasoning, coding, proficiency, and knowledge tests, even beating competitors like Meta's LLaMA 2.

7.	6 Sept, on Google’s 25-year anniversary, Jeff Dean, Chief Scientist of Google DeepMind and Google Research, [posted on Twitter](https://twitter.com/JeffDean/status/1699197621934366946) about his work experience at Google. Jeff said, “It has been deeply gratifying to work on incredibly exciting computer science and AI problems with amazing colleagues, & to help build out a suite of 10+ products that each have more than 1B users all over the world.”

8.	7 Sep, [Mojo is formally released](https://www.modular.com/blog/mojo-its-finally-here). According to Modular, “Mojo is a new programming language for AI developers that will grow into being a superset of Python over time. It already supports integrating with arbitrary Python code seamlessly and has a scalable programming model to target performance-critical systems, including accelerators (e.g. GPUs) that are pervasive in AI.” Mojo combines the best of dynamic and static languages together, and can achieve up to 68,000x the performance of Python today. Other features of Mojo include writing everything in one language, unlocking python performance, accessing the entire Python ecosystem, and upgrading AI workloads.

9.	7 Sep, [Google published a paper](https://arxiv.org/pdf/2309.03409.pdf) “Large Language Models As Optimizers”. In the paper, researchers propose Optimization by PROmpting (OPRO), a simple and effective approach to leverage large language models (LLMs) as optimizers, where the optimization task is described in natural language. In each optimization step, the LLM generates new solutions from the prompt that contains previously generated solutions with their values, then the new solutions are evaluated and added to the prompt for the next optimization step. Experiments show that the best prompts optimized by OPRO outperform human-designed prompts by up to 8% on GSM8K, and by up to 50% on Big-Bench Hard tasks.


**3 Sep 2023**

1.	27 Aug, [according to Techxplore](https://techxplore.com/news/2023-08-ibm-core-mixed-signal-in-memory-chip.html), IBM developed a new 64-core missed-signal in-memory computing chip to better supper support the computations of deep neural networks. The 64-core chip, presented in a paper in [Nature Electronics](https://www.nature.com/articles/s41928-023-01010-1), has so far attained highly promising results, retaining the accuracy of deep learning algorithms, while reducing computation times and energy consumption.

2.	28 Aug, [OpenAI released ChatGPT Enterprise](https://openai.com/blog/introducing-chatgpt-enterprise),which offers enterprise-grade security and privacy, unlimited higher-speed GPT-4 access, longer context windows for processing longer inputs, advanced data analysis capabilities, customization options, and much more. A new admin console lets users manage team members easily and offers domain verification, SSO, and usage insights, allowing for large-scale deployment into enterprise. See our privacy page and our Trust Portal for more details on how we treat your data. However, enterprise data still need to upload to OpenAI to remember all the data.

3.	28 Aug, according to [Semianalysis](https://www.semianalysis.com/p/google-gemini-eats-the-world-gemini), The GPU-Rich companies have 20k+ A/H100 GPUs and are attracting top talent. The GPU-Poor startups and open-source researchers are struggling with far fewer GPUs, and spending significant time and effort attenmptging to do things that simply don’t help, or frakly matter, and an extremely counter-productive use of their skills and time. While the key here is everyone from Meta to Microsoft to startups are simply serving as a pipeline of capital to Nvidia’s bank account, Google – the most compute r rich firm in the world, is one potential savior of Nvidia slavery. Google, which has its unbeatably efficient infrastureture, has already begun training Gemini, the next generation LLM.

4.	30 Aug, Google had its [Google Cloud Next 2023](https://cloud.google.com/blog/topics/google-cloud-next/welcome-to-google-cloud-next-23). In the conference, Google announced several new projects including AI-optimized Infrastructure: The most advanced AI-optimized infrastructure for companies to train and serve models. Vertex AI: Developer tools to build models and AI-powered applications, with major advancements to Vertex AI for creating custom models and building custom Search and Conversation apps with enterprise data;  Duet AI: Duet AI is an always-on AI collaborator that is deeply integrated in Google Workspace and Google Cloud. Duet AI in Workspace gives every user a writing helper, a spreadsheet expert, a project manager, a note taker for meetings, and a creative visual designer, and is now generally available.

5.	30 Aug, [Nature published a paper](https://www.nature.com/articles/s41586-023-06419-4) by researchers from University of Zurich , “Champion-level drone racing using deep reinforcement learning”. The paper discusses First-person view (FPV) drone racing, where professional pilots navigate high-speed drones through 3D circuits while viewing the world through onboard cameras. It highlights the challenge of creating autonomous drones that can race at a professional level by relying solely on onboard sensors. The research project introduces Swift, an autonomous system that achieved the level of human world champions by combining deep reinforcement learning in simulations with real-world data. Swift competed against three human champions, winning multiple races and setting the fastest recorded race time. This achievement is seen as a significant milestone in mobile robotics and machine intelligence, with potential applications in other physical systems.

6.	30 Aug, [Cryptoslate.com reported](https://cryptoslate.com/chatgpt-drives-openai-toward-1b-revenue-goal-after-losing-540m-in-2022/) that ChatGPT drives OpenAI toward $1B revenue goal after losing $540M in 2022. The report indicated that the AI startup has reportedly seen a substantial boost in its monthly revenue to around $80 million. This marks a significant increase from its previous revenue of $28 million, which coincides with the introduction of fees for its widely-used chatbot, ChatGPT. Meanwhile, The Information reported that OpenAI lost around $540 million last year while developing GPT-4 and ChatGPT.

7.	1 Sep, [Science published paper](https://www.science.org/doi/epdf/10.1126/science.ade4401) from Google, “A principal odor map unifies diverse tasks inolfactory perception”. The paper discusses the challenge of connecting molecular structures to how we perceive odors. The authors used graph neural networks to create a Principal Odor Map (POM) that accurately represents the relationships between different odors. This POM was able to predict the quality of odors, even for ones that hadn't been previously characterized. In fact, the model's predictions were as reliable as those of a human expert. The POM outperformed other chemoinformatic models in various odor prediction tasks, demonstrating its effectiveness in encoding general structure-odor relationships. This approach has the potential to revolutionize odor prediction and could lead to the digitization of odors.



**27 Aug 2023**
1.	Meta recently released [RoboAgent]( https://robopen.github.io/) with [paper]( https://robopen.github.io/media/roboagent.pdf) “RoboAgent: Generalization and Efficiency in Robot Manipulation via Semantic Augmentations and Action Chunking”. RoboAgent can efficiently acquire a wide diversity of non-trivial skills and can generalize them to diverse unseen scenarios. Trained merely on 7500 trajectories, RoboAgent can exhibit a diverse set of 12 non-trivial manipulation skills (beyond picking/pushing, including articulated object manipulation and object re-orientation) across 38 tasks, and can generalize them to 100s of diverse unseen scenarios (involving unseen objects, unseen tasks, and to completely unseen kitchens). RoboAgent can also evolve its capabilities with new experiences.

2.	19 Aug, [according to BGR](https://bgr.com/tech/openai-may-have-to-wipe-chatgpt-and-start-over/), OpenAI, the company behind the popular generative AI tool ChatGPT, could be forced to wipe its chatbot and start over completely, according to a new report from NPR (via Ars Technica). The wipe may come as part of a potential lawsuit which could also see OpenAI fined up to $150,000 for each piece of copyrighted material used to train the language model.

3.	21 Aug, [according to The Times of Israel](https://www.timesofisrael.com/ai-likely-to-augment-rather-than-destroy-jobs-un-study-finds/), Artificial Intelligence is more likely to augment jobs than to destroy them, a UN study indicated on Monday, at a time of growing anxiety over the potential impact of the technology. Countries should therefore design policies to support an “orderly, fair and consultative” shift, the report authors said, stressing that “outcomes of the technological transition are not pre-determined.”

4.	21 Aug, another agent related [project released](https://human-world-model.github.io/) by researchers from CMU with [paper](https://arxiv.org/pdf/2308.10901.pdf) “Structured World Models from Human Videos”. Inspired by the success of learning from large-scale datasets in the fields of computer vision and natural language, researchers believe that in order to efficiently learn, a robot must be able to leverage internet-scale, human video data. Humans interact with the world in many interesting ways, which can allow a robot to not only build an understanding of useful actions and affordances but also how these actions affect the world for manipulation. The proposed approach builds a structured, human-centric action space grounded in visual affordances learned from human videos. The approach of affordance-space world models enables different robots to learn various manipulation skills in complex settings, in under 30 minutes of interaction.

5.	21 Aug, researchers from UC Berkeley published a [paper](https://arxiv.org/pdf/2308.10897.pdf) “Can Language Models Learn to Listen?”. Given a video of a listener and speaker pair, researchers extract text corresponding to the spoken words of the speaker. They fine-tune a pretrained large language model to autoregressively generate realistic 3D listener motion in response to the input transcript. The method generates semantically meaningful gestures (e.g. an appropriately timed smile inferred from “amazing”) that synchronously flow with the conversation. The model can optionally render the output of the approach as photorealistic video. [Watch this](https://www.youtube.com/watch?v=djpSOhdIU8M)

6.	21 Aug, Google published a [paper](https://arxiv.org/pdf/2308.08998.pdf) “Reinforced Self-Training (ReST) for Language Modeling”. Given an initial LLM policy, ReST produces a dataset by generating samples from the policy, which are then used to improve the LLM policy using offline RL algorithms. ReST is more efficient than typical online RLHF methods because the training dataset is produced offline, which allows data reuse. Experimental results show that ReST can substantially improve translation quality, as measured by automated metrics and human evaluation on machine translation benchmarks in a compute and sample-efficient manner.

7.	21 Aug, [According to Reuters](https://www.reuters.com/legal/ai-generated-art-cannot-receive-copyrights-us-court-says-2023-08-21/), a work of art created by artificial intelligence without any human input cannot be copyrighted under U.S. law, a U.S. court in Washington, D.C., has ruled.

8.	22 Aug, [Meta released SeamlessM4T](https://about.fb.com/news/2023/08/seamlessm4t-ai-translation-model/), a Multimodal AI Model for Speech and Text Translations. SeamlessM4T is the first all-in-one multilingual multimodal AI translation and transcription model. his single model can perform speech-to-text, speech-to-speech, text-to-speech, and text-to-text translations for up to 100 languages depending on the task. [Project is here]( https://github.com/facebookresearch/seamless_communication)

9.	22 Aug, [according to Anaconda](https://www.anaconda.com/blog/announcing-python-in-excel-next-level-data-analysis-for-all), Anaconda and Microsoft announced a groundbreaking innovation: Python in Excel. This marks a transformation in how Excel users and Python practitioners approach their work. 

10.	22 Aug, [according to theVerge](https://www.theverge.com/2023/8/21/23840705/new-york-times-openai-web-crawler-ai-gpt), The New York Times blocks Open AI’s Web Crawler. No further comments from both side so far.

11.	22 Aug, a new SQLCoder project, [Defog SQLCoder](https://github.com/defog-ai/sqlcoder) was released last week. SQLCoder is a 15B parameter model that outperforms gpt-3.5-turbo for natural language to SQL generation tasks on sql-eval framework, and significantly outperforms all popular open-source models. It also significantly outperforms text-davinci-003, a model that's more than 10 times its size.

12.	22 Aug, a group of research from different institutes published a [paper](https://arxiv.org/pdf/2308.08708.pdf) “Consciousness in Artificial Intelligence: Insights from the Science of Consciousness”. The researchers survey several prominent scientific theories of consciousness, including recurrent processing theory, global workspace theory, higherorder theories, predictive processing, and attention schema theory. From these theories, researchers derive ”indicator properties” of consciousness, elucidated in computational terms that can be used to assess AI systems for these properties. Analysis suggests that no current AI systems are conscious, but also suggests that there are no obvious technical barriers to building AI systems which satisfy these indicators.

13.	23 Aug, according to [MarketChpost](https://www.marktechpost.com/2023/08/23/ai2-unveils-dolma-a-3-trillion-token-corpus-pioneering-transparency-in-language-model-research/), AI2 open source Dolma, a 3 trillion token corpus pioneering transparency in language model research. Opacity of datasets used by big players hinders external researchers’ ability to critically analyse and enhancing existing models. Dolma, the brainchild of AI2, emerges as a beacon of openness in a landscape shrouded in secrecy. With an all-encompassing dataset spanning web content, academic literature, code, and more, Dolma strives to empower the research community by granting them the tools to build, dissect, and optimize their language models independently.

14.	24 Aug, Meta released [Code Llama](https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/), Open Foundation Models for Code. The code is available from [Github]( https://github.com/facebookresearch/codellama). Code Llama is a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. Llama code include foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. Code Llama reaches state-of-the-art performance among open models on several code benchmarks, with scores of up to 53% and 55% on HumanEval and MBPP, respectively.

15.	25 Aug, [Phind.com](https://www.phind.com/blog/code-llama-beats-gpt4) fined tuned CodeLlama-34B and 34B-Python models with 32 A100 GPU on an internal Phind dataset that achieved 67.6% and 69.5% pass@1 on HumanEval, respectively, while GPT-4 achieved 67%. Phind’s models are available to download from [huggingface]( https://huggingface.co/Phind/Phind-CodeLlama-34B-v1)

16.	19-25 Aug, [IJCAI 2023](https://ijcai-23.org/) was hold in Macao. Distinguished papers include “Levin Tree Search with Context Models”, “SAT-Based PAC Learning of Description Logic Concepts”, and “Safe Reinforcement Learning via Probabilistic Logic Shields”.

17.	26 Aug, [WizardLM_AI](https://twitter.com/WizardLM_AI/status/1695396881218859374) twittered that “WizardCoder-34B surpasses GPT-4, ChatGPT-3.5 and Claude-2 on HumanEval with 73.2% pass@1”. The model weights are available [here](https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0).



**20 Aug 2023**
1.	14 Aug, Meta published a [paper](https://arxiv.org/pdf/2308.06259.pdf) “Self-Alignment with Instruction Backtranslation”. The paper present a scalable method to build a high quality instruction following language model by automatically labelling human-written text with corresponding instructions. The model, named instruction backtranslation, starts with a language model finetuned on a small amount of seed data, and a given web corpus. The seed model is used to construct training examples by generating instruction prompts for web documents (self-augmentation), and then selecting high quality examples from among these candidates (self-curation). This data is then used to finetune a stronger model. Finetuning LLaMa on two iterations of our approach yields a model that outperforms all other LLaMa-based models, demonstrating highly effective self-alignment.

2.	14 Aug, Alex Graves published a [paper](https://arxiv.org/pdf/2308.06259.pdf) “Bayesian Flow Networks”, which is [described](https://www.reddit.com/r/MachineLearning/comments/15rrljw/bayesian_flow_networks/?rdt=50628) as “Another Alex Graves paper that will take 10 years for the community to fully digest.” One of the author of the paper, Rupesh Srivastava, [summarized it](https://twitter.com/rupspace/status/1691584987148218841) as  the researchers “present a new perspective on the ideas related to diffusion models. BFNs combine Bayesian inference and neural nets to yield a model class with simple objectives that gracefully extends to discrete data.”

3.	14 Aug, Meta released a [paper](https://arxiv.org/pdf/2308.07317.pdf) “Platypus: Quick, Cheap, and Powerful Refinement of LLMs”. Platypus is a family of fine-tuned and merged Large Language Models that achieves the strongest performance and currently stands at first place in HuggingFace’s Open LLM Leaderboard as of the release date of this work. In particular, a 13B Platypus model can be trained on a single A100 GPU using 25k questions in 5 hours.

4.	14 Aug, researchers from Microsoft published [paper](https://arxiv.org/pdf/2308.06873.pdf) “SpeechX: Neural Codec Language Model as a Versatile Speech Transformer”. Researcher find existing models still face limitations in handling diverse audio-text speech generation tasks involving transforming input speech and processing audio captured in adverse acoustic conditions. The introduced SpeechX is a versatile speech generation model capable of zero-shot TTS and various speech transformation tasks, dealing with both clean and noisy signals. SpeechX achieves comparable or superior performance to specialized models across tasks.

5.	14 Aug, while some [report](https://technext24.com/2023/08/14/chatgpt-costs-700000-daily-openai/) estimated that ChatGPT costs $700,000 to run daily, OpenAI may go bankrupt in 2024; others believe that ChatGPT is probably a small profit center right now.

6.	14 Aug,  according to [BusinessInsider](https://www.businessinsider.com/ai-radically-reshape-job-market-global-economy-employee-labor-innovation-2023-8), the rise of AI is poised to disrupt the global economy, potentially eliminating millions of jobs as AI tools become more accessible and advanced. A surge in public adoption of AI is predicted to reshape industries and labor markets, with estimates indicating that over 300 million jobs could be affected globally. While AI's transformative potential could contribute trillions to the economy, it calls for urgent preparation by governments, businesses, and workers to manage the impending upheaval and ensure a smoother transition through retraining and workforce adaptation.

7.	14 Aug, according [seroundtable](https://www.seroundtable.com/microsoft-bing-chat-outperforms-gpt-4-35873.html), Microsoft Bing's CEO, Mikhail Parakhin said on Twitter that Bing Chat outperforms raw GPT-4 but it comes at an expense. He said, "It is outperforming according to our measurements," when someone said they think Bing Chat beats out GPT-4 from OpenAI. Keep in mind, Bing uses GPT-4 from OpenAI, but as Mikhail Parakhin explained and as many of you already know, "Bing is using retrieval-augmented inference." He adds that doing all this is much more expensive, he said "Yes, we have that offering, it ends up pretty pricey, as it requires multiple model calls + Search calls, so far it’s been only used by a few companies."

8.	15 Aug, according to [Businessinsider](https://www.businessinsider.com/chatgpt-isnt-good-enough-to-take-jobs-unlikely-mass-layoffs-2023-8), Despite initial fears of AI causing mass layoffs, the reality is that AI, exemplified by ChatGPT, hasn't proven itself capable enough to replace most jobs. The anticipated automation wave has not led to widespread unemployment; the adoption of AI tools has been widely embraced, but the impact on jobs has been less dramatic than predicted. Many companies find AI useful for specific tasks but not advanced enough to handle the complexity of human roles. While some jobs will be affected, the complexities of tasks and the need for human supervision are hindrances to complete automation. The transition to AI-driven work is intricate, and the anticipated AI-driven unemployment has not materialized as predicted.

9.	16 Aug, [OpanAI added a new content moderation feature](https://openai.com/blog/using-gpt-4-for-content-moderation#LilianWeng). Content moderation demands meticulous effort, sensitivity, a profound understanding of context, as well as quick adaptation to new use cases, making it both time consuming and challenging. The new feature makes the process of developing and customizing content policies is trimmed down from months to hours. 1) Once a policy guideline is written, policy experts can create a golden set of data by identifying a small number of examples and assigning them labels according to the policy.  2)Then, GPT-4 reads the policy and assigns labels to the same dataset, without seeing the answers. 3) By examining the discrepancies between GPT-4’s judgments and those of a human, the policy experts can ask GPT-4 to come up with reasoning behind its labels, analyze the ambiguity in policy definitions, resolve confusion and provide further clarification in the policy accordingly. Repeat steps 2 and 3 until it is satisfied with the policy quality. This iterative process yields refined content policies that are translated into classifiers, enabling the deployment of the policy and content moderation at scale.

10.	16 Aug, according to [Venturebeat](https://venturebeat.com/ai/consulting-giant-mckinsey-unveils-its-own-generative-ai-tool-for-employees-lilli/), McKinsey is debuting a gen AI tool of its own: Lilli, a new chat application for employees. The tool serves up information, insights, data, plans, and even recommends the most applicable internal experts for consulting projects, all based on more than 100,000 documents and interview transcripts. The interface will look familiar to those who have used other public-facing text-to-text based gen AI tools such as OpenAI’s ChatGPT and Anthropic’s Claude 2. Lilli leverages currently available LLMs, including those developed by McKinsey partner Cohere as well as OpenAI on the Microsoft Azure platform, to inform its GenAI Chat and natural language processing (NLP) capabilities.

11.	16 Aug, as [reported by Independent](https://www.independent.co.uk/tech/google-quantum-computer-apocalypse-encryption-password-security-b2393516.html), Google is taking steps to address the potential security threat posed by quantum computers, known as the "quantum apocalypse." Quantum computers have the capability to break current encryption methods that protect sensitive data. To counter this, Google has integrated a hybrid cryptographic algorithm, X25519Kyber768, into Chrome to resist attacks from future quantum computers. While quantum computers capable of breaking current encryption are projected to be years away, Google's move is aimed at securing data now to prevent it from being intercepted and decrypted in the future.

12.	16 Aug, according to [BusinessInsider](https://www.businessinsider.com/databricks-ali-ghodsi-unqualified-ceos-dont-know-ai-data-2023-8), Databricks’ CEO Ali Ghodsi said that “I run a $38 billion software company. In 10 years, CEOs who don't understand data and AI won't be eligible for the top job in any industry.” As generative AI becomes more ubiquitous, Ghodsi says companies that prioritize data will have an advantage.

13.	16 Aug, Lamini, an AI company, [released a blog](https://www.lamini.ai/blog/one-billion-times-faster-finetuning-with-lamini-peft) “One Billion Times Faster Finetuning with Lamini PEFT”, in brief, Parameter-efficient finetuning (PEFT) makes it one billion times faster to scale unlimited LLM variations for specialized tasks. Chain and switch between thousands of finetuned LLMs - from months down to just milliseconds.

14.	16 Aug, according to [theVerge](https://www.theverge.com/2023/8/15/23833045/google-artificial-intelligence-summary-chrome-sge), Google’s AI-powered article summaries are rolling out for iOS and Android first, before coming to Chrome on the desktop. The Search Generative Experience (SGE) project will be able to summarize articles users are reading on the web, according to a Google blog post. SGE can already summarize search results so that users don’t have to scroll forever to find what they are looking for, and this new feature is designed to take that further by helping users out after they are actually clicked a link.

15.	17 Aug, according to [financial times](https://www.ft.com/content/ed323f48-fe86-4d22-8151-eed15581c337), The hype around generative AI is met with skepticism as doubts arise about its effectiveness and practical applications. Technologist Gary Marcus questions the technology's reliability, noting its tendency to produce inaccurate content. Concerns also center on generative AI's impact on future training data, potentially leading to misinformation. While investors argue for its value as a productivity tool and problem solver, doubts persist about its true potential. Amid the uncertainty, cloud computing providers and chip manufacturers benefit, while the longevity of generative AI's impact remains uncertain.

16.	19 Aug, according to [gizmodo](https://gizmodo.com.au/2023/08/metas-next-big-open-source-ai-dump-will-reportedly-be-a-code-generating-bot/), Meta may release a Code-generation bot as soon as next week. The reporter from Information who spoke to two anonymous sources with direct knowledge of the AI, this new model dubbed “Code Llama” will be open source and available free online. This is consistent with the company’s strategy so far of releasing widely available AI software that makes developing new customizable AI models much easier for companies who don’t want to pay OpenAI or others for the privilege.



**14 Aug 2023**

1.	7 Aug, [according to searchenginejournal](https://www.searchenginejournal.com/openai-launches-gptbot-how-to-restrict-access/493394/#close), OpenAI launches GPTBot, a web crawler which will be used the company to improve its AI models; it also has instructions on how to restrict or limit its access. The news has sparked a debate on Hacker News around the ethics and legality of using scraped web data to train proprietary AI systems. Some think OpenAI, like other person learning from online content, can freely use public web data; others believe if OpenAI use the data to make profit, the profit should be shared among the data owners.
2.	7 Aug, Anthropic.AI published a [paper](https://arxiv.org/pdf/2308.03296.pdf) “Studying Large Language Model Generalization with Influence Functions”. The paper argues that LLMs are difficult to understand, but influence functions can help. Researchers developed a method for scaling influence functions to large models and found that: LLMs do not simply memorize training sequences; Larger models generalize better; Influence is evenly distributed, but different layers exhibit distinct patterns; LLMs are sensitive to word order; Role-playing behavior is primarily driven by imitation. These findings suggest that LLMs are more complex and nuanced than previously thought.
3.	6-9 Aug, [SIGGRAPH](https://s2023.siggraph.org/) was holding  at Los Angeles. This is its 50th annual conference covering topics such as production & animation, research & education, arts & design, gaming & interactive and others. Jensen Huang delivered a keynote speech. He introduced Grace Hopper, a new super chip for AI, as computing’s “killer app”. The chip is ten times faster, much cheaper and has lower power consumptions. He also repeated his famous word: the more you buy, the more you save.
4.	7 Aug, researcher from DeepMind published a [paper](https://arxiv.org/pdf/2308.03958.pdf) “Simple synthetic data reduces sycophancy in large language models”. Sycophancy is an undesirable behavior where models tailor their responses to follow a human user’s view even when that view is not objectively correct (e.g., adapting liberal views once a user reveals that they are liberal). To address the issue, researchers present a straightforward synthetic-data intervention that takes public NLP tasks and encourages models to be robust to user opinions on these tasks. Adding these data in a lightweight finetuning step can significantly reduce sycophantic behavior on held-out prompts.
5.	8 Aug, [according to BlackBerry](https://blogs.blackberry.com/en/2023/08/why-companies-ban-chatgpt-ai), 75% of organizations worldwide set to ban chatGPT and generative AI apps on work devices. The data is based on a BlackBerry survey of 2,000 IT decision-makers across the US, Canada, the UK, France, Germany, the Netherlands, Japan, and Australia. Potential risk to data security and privacy is the biggest reason (67%) survey respondents cited for moving to block ChatGPT and similar generative AI tools. The next greatest concern (57%) is risk to corporate reputation.  
6.	8 Aug, [Stability.AI announced StableCode](https://stability.ai/blog/stablecode-llm-generative-ai-coding), according to Stability.AI, StableCode offers a unique way for developers to become more efficient by using three different models to help in their coding. The base model was first trained on a diverse set of programming languages from the stack-dataset (v1.2) from BigCode and then trained further with popular languages like Python, Go, Java, Javascript, C, markdown and C++.  In total, we trained our models on 560B tokens of code on our HPC cluster.
7.	9 Aug, [IBM is planning](https://newsroom.ibm.com/2023-08-09-IBM-Plans-to-Make-Llama-2-Available-within-its-Watsonx-AI-and-Data-Platform) to host Meta's Llama 2-chat 70 billion parameter model in the watsonx.ai studio, with early access now available to select clients and partners. This will build on IBM's collaboration with Meta on open innovation for AI, including work with open source projects developed by Meta – such as the PyTorch machine learning framework and the Presto query engine used in watsonx.data.
8.	9 Aug, [Biden-Harris Administration launches](https://www.whitehouse.gov/briefing-room/statements-releases/2023/08/09/biden-harris-administration-launches-artificial-intelligence-cyber-challenge-to-protect-americas-critical-software/) AI cyber challenge, together with Microsoft, OpenAI, Google and Anthropic, to pretect America’s critical software. DARPA will host an open competition in which the competitor that best secures vital software will win millions of dollars in prizes. AI companies will make their cutting-edge technology—some of the most powerful AI systems in the world—available for competitors to use in designing new cybersecurity solutions.
9.	10 Aug, Stanford researchers open source the famous [“Stanford Smallville”](https://github.com/joonspk-research/generative_agents). In their [paper](arxiv.org/abs/2304.03442), 25 AI agents inhabit a digital Westworld, unaware that they are living in a simulation. They go to work, gossip, organize socials, make new friends, and even fall in love. Each has unique personality and backstory. The github repository contains the core simulation module for generative agents—computational agents that simulate believable human behaviors—and their game environment. 
10.	10 Aug, Researchers from Google recently [published a blog](https://pair.withgoogle.com/explorables/grokking/#:~:text=In%202021%2C%20researchers%20made%20a,after%20training%20for%20much%20longer.) “Do Machine Learning Models Memorize or Generalize?”. As we know, we train a ML model to generalize rather than memorize. In the blog, the authors use the term grokking to describe the phenomenon where generalization seems to happen abruptly and long after fitting the training data. While it isn’t yet clear how to apply these techniques to today’s largest models, starting small makes it easier to develop intuitions as we progress towards answering these critical questions about large language models.
11.	10 Aug, a [paper](https://arxiv.org/pdf/2308.03762.pdf) with title “GPT-4 Can’t Reason” raised [interesting discussions](https://news.ycombinator.com/item?id=37050257) on prompting engineering when using ChatGPT-like models, including GPT-4. Some argued that the author of the paper may have used an outdated version of GPT-4 , or have been using the wrong prompt for GPT-4. There are many different ways to prompt engineer GPT-4, and the best approach depends on the specific task at hand; others believe prompting engineering is cheating, but others argued that it is simply a way to help GPT-4  to perform better.
12.	11 Aug, researchers from Microsoft and Uni. Of Southern California released [UniversalNER](https://arxiv.org/abs/2308.03279). The researchers propose a general recipe for targeted distilling where they train student models using mission-focused instruction tuning for a broad application class such as open information extraction. Researchers show that this can maximally replicate LLM’s capabilities for the given application class, while preserving its generalizability across semantic types and domains. Using NER as a case study, they successfully distill these capabilities from LLMs into a much smaller model UniversalNER that can recognize diverse types of entities or concepts in text corpora from a wide range of domains. UniversalNER surpasses existing instruction-tuned models at the same size (e.g., Alpaca, Vicuna) by a large margin, and shows substantially better performance to ChatGPT.



**6 Aug 2023**
1.	Kaiming He, [announced that](https://kaiminghe.github.io/) he will join Department of Electrical Engineering and Computer Science at MIT in 2024. His total Google Scholar citations exceed 460,000 + times, and he will become the first at MIT. Previously, he worked at FAIR. His research results [ResNet](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) is one of the cornerstone papers in the field of Deep learning.
2.	Recently, Stanford Uni published a [paper](https://arxiv.org/pdf/2307.15189.pdf): “Med-Flamingo: a multimodal medical few-shot learner”. Based on OpenFlamingo-9B, researchers continue pre-training on paired and interleaved medical image-text data from publications. Med-Flamingo improves performance in generative medical VQA by up to 20% in clinician’s rating and firstly enables multimodal medical few-shot adaptations, such as rationale generation and textbooks.
3.	1 Aug, according to [Search Engine Journal](https://www.searchenginejournal.com/openai-files-trademark-application-gpt-5/493040/#close), OpenAI has filed a trademark application for “GPT-5”. The application covers a wide range of software related to language models and AI, such as downloadable computer programs and software related to language models, artificial production of human speech and text, natural language processing, generation, understanding, and analysis. However, as Sam Altman said recently, “We have a lot of work to do before GPT 5. It takes a lot of time for it. We are not certainly close to it. There needs to be more safety audits. I wish I could tell you about the timeline of the next GPT”.
4.	1 Aug, [LLM-UTILS published](https://gpus.llm-utils.org/nvidia-h100-gpus-supply-and-demand/) a blog discussing the supply and demand of GPUs. The blog commented that as of August 2023, it seems AI might be bottlenecked by the supply of GPUs. This comment is supported by Sam Altman, he said that OpenAI is GPU-limited and it’s delaying their short term plans (fine-tuning, dedicated capacity, 32k context windows, multimodality). Elon Must also said that “GPUs are at this point considerably harder to get than drugs.” The blog further discussed what do we want to know about the bottleneck, including what’s causing it, how long will it last, and wha’t going to help resolved it.
5.	1 Aug, researchers from Google and Uni of Washington [published a paper](https://arxiv.org/pdf/2308.00675.pdf) “Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models”. Instead of providing a few demonstrations of the tool’s usage, the paper provides an alternative to demonstrations: tool documentation, descriptions of the individual tool usage. Experimental results demonstrate the zero-shot documentation is on par or better than few-shot without documentation.
6.	2 Aug, Google published a [paper on Nature](https://www.nature.com/articles/s41586-023-06221-2): “Scientific discovery in the age of artificial intelligence”. The paper indicates that AI is being increasingly integrated into scientific discovery to augment and accelerate research, helping scientists to generate hypotheses, design experiments, collect and interpret large datasets, and gain insights that might not have been possible using traditional scientific methods alone. Researchers then examine breakthroughs over the past decade that include self-supervised learning, which allows models to be trained on vast amounts of unlabelled data, and geometric deep learning, which leverages knowledge about the structure of scientific data to enhance model accuracy and efficiency. The paper further suggests that both developers and users of AI tools need a better understanding of when such approaches need improvement, and challenges posed by poor data quality and stewardship remain.
7.	2 Aug, Meta released its MusicGen project, [Audiocraft](https://github.com/facebookresearch/audiocraft). Audiocraft is a library for audio processing and generation with deep learning. It features the state-of-the-art EnCodec audio compressor / tokenizer, along with MusicGen, a simple and controllable music generation LM with textual and melodic conditioning.
8.	Mckinsey [released a survey](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2023-generative-ais-breakout-year?cid=aisurge2023-soc--mar-mar--07/23-i1a--bam-ip&linkId=227872978#/) titled “The state of AI in 2023: Generative AI’s breakout year”. The survey confirms the explosive growth of generative AI (gen AI) tools. Less than a year after many of these tools debuted, one-third of the survey respondents say their organizations are using gen AI regularly in at least one business function. The organizations that have already embedded AI capabilities have been the first to explore gen AI’s potential, and those seeing the most value from more traditional AI capabilities—a group we call AI high performers—are already outpacing others in their adoption of gen AI tools.
9.	3 Aug, [IBM reported](https://research.ibm.com/blog/nasa-hugging-face-ibm) that IBM and NASA open source the largest geospatial AI foundation model on [Hugging Face](https://huggingface.co/ibm-nasa-geospatial). The move aims to widen access to NASA satellite data (250,000 terabytes) and accelerate climate-related discoveries by using a model built by IBM.
10.	3 Aug, Microsoft announced [project Rumi](https://www.maginative.com/article/project-rumi-augmenting-ai-understanding-through-multimodal-paralinguistic-prompting/), which aims to incorporate paralinguistic input, such as intonation, gestures, and facial expressions, into prompt-based interactions with LLMs. Rumi leverages separately trained vision and audio-based models to assess sentiment from cognitive and physiological data in real-time. The system extracts non-verbal cues from video and voice inputs in real-time, creating paralinguistic tokens that augment the standard lexical input to existing LLMs like GPT4. Microsoft's future plans for Project Rumi include improving the performance of existing models and incorporating additional signals, like heart rate variability derived from standard video, cognitive, and ambient sensing. These explorations paint a picture of a more dynamic, sensitive AI capable of understanding the complexity of human interaction.



**30 July 2023**
1.	19 Jul,  a [paper](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2307.09793.pdf&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571567254%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=Nx2s8Qs1wXqcvi%2FYaGv9zBXTGlC91BSUj1ZalKGG2XM%3D&reserved=0) published by Stanford Uni. revealed that to date, nearly 16K (15,821) Text Generation models have been uploaded to Hugging Face. 
2.	22 Jul, [according to Reuters](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.reuters.com%2Ftechnology%2Fopenai-google-others-pledge-watermark-ai-content-safety-white-house-2023-07-21%2F&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571567254%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=giSWo1jnuNaFyZJaTQQaMQd%2FvvFAm5I%2FwB%2BBEsl%2FYPI%3D&reserved=0), AI companies including OpenAI, Alphabet and Meta Platforms have made voluntary commitments to the White House to implement measures such as watermarking AI-generated content to help make the technology safer, President Joe Biden announced on Friday. The companies - which also include Anthropic, Inflection, Amazon.com and OpenAI partner Microsoft - pledged to thoroughly test systems before releasing them and share information about how to reduce risks and invest in cybersecurity.
3.	23-29 Jul. [ICML 2023](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Ficml.cc%2F&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571567254%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=XrTqRYqIURwmY7HxqnXXA6lzFD%2FqcW6LcIxzIC0z7Wg%3D&reserved=0). All published paper titles can be found [here](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Ficml.cc%2Fvirtual%2F2023%2Fpapers.html%3Ffilter%3Dtitles&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571567254%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=%2F9VBhsYbaROsWyY%2FkPkYLhk9GAegRhJ93r5tOtrv1RY%3D&reserved=0), rewards paper titles can be found [here](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Ficml.cc%2Fvirtual%2F2023%2Fawards_detail&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571567254%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=uiK98xlINGLHXKrMiO%2BPDy6s%2FGQtMio7m%2Bz3V2T7RIA%3D&reserved=0). Need register to access the papers
4.	24th Jul, Evan Miller [published a blog](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.evanmiller.org%2Fattention-is-off-by-one.html&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571567254%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=YyFOS2S4xQfttpjfMQUHsHTdPLzov10A%2B6MOmVROhyA%3D&reserved=0), “Attention is Off By One”. Evan argues that the softmax formula applied on the Q multiply transpose of V divided by square-root of d should be fixed by adding one to the denominator, which is called the softmar1. He named the new attention as QuietAttention because it allows one attention head to simply “pass” rather than must add something to the output vector. The proposed QuietAttention is expected to alleviate outlier issues of attention which occur in white space and punctuation positions.
5.	24 Jul, researchers from UCLA, IBM, et al. published a paper “Injecting the 3D World into Large Language Models”, In [this work](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fvis-www.cs.umass.edu%2F3dllm%2F&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571567254%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=Nu%2FZSEooXdXLagj3jfeGWuYPdZR9hEVtoEIY2eEglcg%3D&reserved=0), researchers propose to inject the 3D world into large language models, and introduce a whole new family of 3D-LLMs. Specifically, 3D-LLMs can take 3D point clouds and their features as input and perform a diverse set of 3D-related tasks, including captioning, dense captioning, 3D question answering, task decomposition, 3D grounding, 3D-assisted dialog, navigation, and so on.
6.	25 Jul, [it is reported](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwindowsreport.com%2Fg3po-ai%2F&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571567254%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=E2MyXhwjgsEjEm%2BFVA55LR2HxLPg76%2B%2BuLPVWSt9WrI%3D&reserved=0) that OpenAI is planning to release its own open-source language model, codenamed G3PO, to response Meta’s LLaMA2 and other open-source LLMs. While the project has a codename, unfortunately, it doesn’t have a release date for now. It seems that OpenAI might be thinking about other endeavors, such as its superlignment project and to achieve AGI in 4 years from now.
7.	26 Jul, Anthropic, Google, Microsoft, and OpenAI are launching the [Frontier Model Forum](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fopenai.com%2Fblog%2Ffrontier-model-forum&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571567254%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=c7PK6qaqhp%2BJ5jBfU4RI6GkzZ1x0an%2FV0BQZYtRwwpk%3D&reserved=0), an industry body focused on ensuring safe and responsible development of frontier AI models. The Forum aims to help (i) advance AI safety research to promote responsible development of frontier models and minimize potential risks, (ii) identify safety best practices for frontier models, (iii) share knowledge with policymakers, academics, civil society and others to advance responsible AI development; and (iv) support efforts to leverage AI to address society’s biggest challenges.
8.	26 Jul. [Satbility.AI released SDXL 1.0](https://stability.ai/blog/stable-diffusion-sdxl-1-announcement), the next iteration in the evolution of text-to-image generation models. Following the limited, research-only release of SDXL 0.9, the full version of SDXL has been improved to be the world's best open image generation model. SDXL generates images of high quality in virtually any art style and is the best open model for photorealism. Distinct images can be prompted without having any particular ‘feel’ imparted by the model, ensuring absolute freedom of style. SDXL 1.0 is particularly well-tuned for vibrant and accurate colors, with better contrast, lighting, and shadows than its predecessor, all in native 1024x1024 resolution.
9.	26 Jul, [according to itnews](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.itnews.com.au%2Fnews%2Fgoogle-handed-user-data-to-aus-authorities-5525-times-last-year-598413&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571567254%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cEb%2FmmzC9rUucXZC7SUsdBFZdAfxWcw7DirS%2FpxcJD8%3D&reserved=0), Google complied with 5525 of 6335 requests from Australian authorities to disclose user information relating to 7183 accounts last year. Meta and TikTok’s transparency reports are the same; although Meta revealed that it complied with 3563 Australian agencies' requests last year and TikTok complied with 91, during the period - little is known about who made them.
10.	26 Jul, [according to TheVerge](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.theverge.com%2F2023%2F7%2F26%2F23808274%2Fmeta-microsoft-amazon-overture-open-source-mapping&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571567254%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=gdCngplXQBJ1%2BShnqqN8%2B6b76TlHkCtKFwbmPLxyRGM%3D&reserved=0), Meta, Microsoft, Amazon, and the mapping company TomTom have launched an initiative to take on Google Maps and Apple Maps. The four companies formed the Overture Maps Foundation last year with the goal of creating interoperable map products — and now, the group has released its first open map dataset. With this data, third-party developers can create global mapping or navigation products of their own, allowing them to go head-to-head with Google Maps and Apple Maps. According to Overture, the release includes over 59 million places of interest, along with data on buildings, transportation networks, and administrative boundaries.
11.	27 Jul, [according to WashingtonPost](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.washingtonpost.com%2Ftechnology%2F2023%2F07%2F27%2Fsocial-media-research-meta-political-views%2F&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571567254%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=oJGb8dTUulwof%2FnAzqzPS2LQC9NqlAWcbXGzGcm2a3I%3D&reserved=0), the massive study of Facebook and Instagram shows that changing Facebook’s algorithm won’t fix polarization. “Despite the fact that we find this big impact in people’s on-platform experience, we find very little impact in changes to people’s attitudes about politics and even people’s self-reported participation around politics.” Meta’s research results are published on both [Science](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.science.org%2Fcontent%2Farticle%2Fdoes-social-media-polarize-voters-unprecedented-experiments-facebook-users-reveal&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571567254%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=u8cip2sJh%2FkcYHZjJVA5c3n2jLsP09Y2VaXDLeNoNAg%3D&reserved=0) and [Nature](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.nature.com%2Farticles%2Fd41586-023-02420-z&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571723482%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=hmIRqOexb7yzCiC9QcC2St65C%2FvedNt1YUrG8S%2FkjS0%3D&reserved=0).
12.	27 Jul, [according to NY Times](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.nytimes.com%2F2023%2F07%2F27%2Fbusiness%2Fai-chatgpt-safety-research.html&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571723482%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=JlqhfMxkj1AsaGePUhVBjWp%2Fm%2Bllus4xBsbaaqBwg6I%3D&reserved=0), researchers from CMU published a [paper](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2307.15043.pdf&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571723482%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=euiTfl%2BQXX1l0M3o%2BRZLw4WtJVM8%2BrsurtE3vrTGy6I%3D&reserved=0) that showed how anyone could circumvent A.I. safety measures and use any of the leading chatbots to generate nearly unlimited amounts of harmful information. The researchers found that they could break through the guardrails of open source systems by appending a long suffix of characters onto each English-language prompt fed into the system.
13.	27 Jul, a16z proposed [Money on Autopilot](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fa16z.com%2F2023%2F07%2F27%2Fmoney-on-autopilot-ai-personal-finance%2F&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571723482%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=W9W%2Be9%2B3WTN8p9MbNQ6QdeDQDfNPBOKjGGcBSk%2BdHXA%3D&reserved=0), the much-discussed topic of “self-driving money” finally has a chance to achieve its potential. Post-generative AI, we’re in a new world for consumer financial platforms. LLMs, and specifically multi-modal prompts like GPT-4, can process and output both text and images. This enables consumer robot process automation (RPA), which will allow fintech apps to operate on a user’s behalf.
14.	28 Jul, [according to BusinessInsider](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.businessinsider.com%2Fopenai-cant-identify-ai-generated-text-bad-for-internet-models-2023-7&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571723482%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=bvKFq0gVx8RTcgLb%2F1rg1ZxpDK3kdb%2BCoiHFJYZqbcw%3D&reserved=0), OpenAI just admitted it can't identify AI-generated text. "As of July 20, 2023, the AI classifier is no longer available due to its low rate of accuracy,"  OpenAI wrote in a [recent blog](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fopenai.com%2Fblog%2Fnew-ai-classifier-for-indicating-ai-written-text&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571723482%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=KDAjgPC4CaJCEpESJrsk0yfydHaJj8mH0EeSCCaHZGQ%3D&reserved=0). "We are working to incorporate feedback and are currently researching more effective provenance techniques for text." If tech companies use AI-produced data inadvertently to train new models, some researchers worry those models will get worse.
15.	28 Jul, Google released its [Robotics-transformer2 project](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Frobotics-transformer2.github.io%2F&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571723482%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=cylTIuY6WempGlk%2FYksJRS7Vs2uWP6KfMV2l%2FWK3d5s%3D&reserved=0) and a [paper](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Frobotics-transformer2.github.io%2Fassets%2Frt2.pdf&data=05%7C01%7Cd.zhu%40curtin.edu.au%7C56ec33fa33d7422800b908db90ead9a0%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638263110571723482%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=NZdn3QAulqGaV2RKVjSGziBix%2Bd8Pja39J7RfiIURzI%3D&reserved=0) “RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control”. The vision-language-action models (VLA) express the actions as text tokens and incorporate them directly into the training set of the model in the same way as natural language tokens. extensive evaluation (6k evaluation trials) shows that the approach leads to performant robotic policies and enables RT-2 to obtain a range of emergent capabilities from Internet-scale training. This includes significantly improved generalization to novel objects, the ability to interpret commands not present in the robot training data (such as placing an object onto a particular number or icon), and the ability to perform rudimentary reasoning in response to user commands (such as picking up the smallest or largest object, or the one closest to another object). Researchers further show that incorporating chain of thought reasoning allows RT-2 to perform multi-stage semantic reasoning, for example figuring out which object to pick up for use as an improvised hammer (a rock), or which type of drink is best suited for someone who is tired (an energy drink).



**23 July 2023**
1.	A recent [report from OpenUK](https://openuk.uk/wp-content/uploads/2023/07/FINAL-State-of-Open-The-UK-in-2023-Phase-Two-Part-1.pdf) indicates that in 2022, the Gross Value added to the UK economy from Open Source Software is estimated to be £13.59 billion. So what does that mean? Contextualising it with the UK Tech Sector contribution at £50 billion in 2022, the directly attributable contribution from Open Source Software is therefore 27%, more than a quarter of the overall Tech Sector contribution.
2.	17 Jul, Microsoft published a [paper](https://arxiv.org/abs/2307.08621): “Retentive Network: A Successor to Transformer for Large Language Models”. RetNet achieves low-cost inference (i.e., GPU memory, throughput, and latency), training parallelism, and favorable scaling curves compared with Transformer. RetNet makes the “impossible triangle” possible, which achieves training parallelism, good performance, and low inference cost simultaneously. The code will be released within two weeks.
3.	17 Jul, [HPC-AI released its 65 billion](https://www.hpc-ai.tech/blog/large-model-pretraining) parameter large language model. It utilizes the current most widely used large model, LLaMA, to provide an example of the tool’s groundbreaking pre-training solutions for the 65 billion parameter large model which improves the training speed by 38%. This can save enormous amounts for large model enterprises. HPC-AI only needs 32 A100/A800 GPUs to improve pre-training speed by 38% compared to other mainstream options in the industry.
4.	18 Jul, Dao published a [paper](https://tridao.me/publications/flash2/flash2.pdf), FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning. FlashAttention2 (1) tweaks the algorithm to reduce the number of non-matmul FLOPs (2) parallelizes the attention computation, even for a single head, across different thread blocks to increase occupancy, and (3) within each thread block, distributes the work between warps to reduce communication through shared memory. These yield around2× speedup compared to FlashAttention, reaching 50-73% of the theoretical maximum FLOPs/s on A100 and getting close to the efficiency of GEMM operations.
5.	19 Jul, Meta [released LLaMA v2](https://download.llamameta.net/*?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiI0o%7EP01cdTAwMWUjPyIsIlJlc291cmNlIjoiaHR0cHM6XC9cL2Rvd25sb2FkLmxsYW1hbWV0YS5uZXRcLyoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODk4MTkzMzR9fX1dfQ__&Signature=CgIvdOxnfMPih1sAr%7EkkhBGpl0PBj9n9rebxjFEbb6u-aVLYyV1kK2le4B0bSt3jZ9gFFc2pf5XTG%7EauFCE4lo7FSiQ7VRRKIEjpTx9QtGzO%7EvquyTb3sON6YdEtLi4fu%7EBVYk58ce%7E5nK%7EkXvqsuld5zA%7EPaLKB-WXjd-6DwmqUjphv4k6v0Lb7jH0V%7EgCzK3JFuzUwrCUPXInbtDinMnCUPOFu4TW-%7E9QlZVPUaDfqlRvWExDcULe3akb2KEGif37U-P3fLTmrGdIuTSflvqJrUdM33FwbMd2a7s2TSIUcLBD%7EUqvyi43Drx2Cr8zzSFAOVYovwMQMYxUtUGrphQ__&Key-Pair-Id=K15QRJLYKIFSLZ), a series of large language models trained on 40% more data (2 Trillion tokens) than Llama 1, and has doubled the context length to 4096. Meta also provided finetuned dialog models with over 100k samples. Llama 2 outperforms other open source language models on many external benchmarks, including reasoning, coding, proficiency, and knowledge tests.
6.	19 Jul [Reuters reported](https://www.reuters.com/technology/apple-tests-generative-ai-tools-rival-openais-chatgpt-bloomberg-news-2023-07-19/) that Apple is working on AI offering similar to OpenAI’s ChatGPT and Google’s Bard, causing its shares up as much as 2% to a record high. Apple's new virtual assistant summarizes text and answers questions based on data it has been trained with, and the tool essentially replicates Bard, ChatGPT and Bing AI, and works as a web application, according to employees of Apple.
7.	19 Jul, researcher from UCL, EleutherAI, Meta, StabilityAI and others published a [paper](https://arxiv.org/pdf/2307.10169.pdf) “Challenges and Applications of Large Language Models”. The authors believed that due to the fast pace of the field, it is difficult to identify the remaining challenges and already fruitful application areas. They explored the challenges of LLMs from three views: Designing LLMs relates to decisions taken before deployment. Behaviorial challenges occur during deployment. Science challenges hinder academic progress.
8.	20 Jul, Nature published a [paper](https://www.nature.com/articles/d41586-023-02317-x) “How to introduce quantum computers without slowing economic growth”. The researchers 
believe that new ways of simulating materials, optimizing processes and improving machine learning — could transform society. They also suggested that Specialists should work together to create narratives around the usefulness of quantum technologies; however, the technology bottlenecks for quantum computing are unclear, and Would these benefits lead to more products and services that are better tailored to customer needs? What would the impacts be on the wider industrial landscape, and what new business models might emerge?
9.	21 Jul, [StabilityAI released FreeWilly](https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models), the large and mighty instruction finetuned open access language models (FreeWilly1 and FreeWilly2). FreeWilly1 leverages the original LLaMA 65B foundation model and was carefully fine-tuned with a new synthetically-generated dataset using Supervised Fine-Tune (SFT) in standard Alpaca format. Similarly, FreeWilly2 leverages the LLaMA 2 70B foundation model to reach a performance that compares favorably with GPT-3.5 for some tasks.
10.	21 Jul, [according to HDTECH](https://tech.hindustantimes.com/tech/news/sergey-brin-returns-to-google-to-work-on-secret-ai-project-gemini-71689927230676.html), Google’s cofounder Sergey Brin returns to Google to work on the secret AI project Gemini, the company’s highly ambitious general-purpose AI project. Gemini would be a multi-modal foundational model that powers other AI models but no further details are known at the moment.


**16 July 2023**
1. Jul 9 – 14, [ACL 2023](https://2023.aclweb.org/), Annual Meeting of the Association for Computational Linguistics (ACL), which is one of the top natural language processing conferences in the world, was held in Toronto, Canada.
2. Jul 11, Anthropic AI released [Claude 2](https://www.anthropic.com/index/claude-2), Claude 2 has improved performance, longer responses, and can be accessed via API as well as a new public-facing beta website, claude.ai. The latest model scored 76.5% on the multiple choice section of the Bar exam, up from 73.0% with Claude 1.3.
3. Jul 11, according to [Bloomberg](https://www.bloomberg.com/news/articles/2023-07-11/ai-researcher-who-helped-write-landmark-paper-is-leaving-google), AI Researcher Who Helped Write Landmark Paper Is Leaving Google, and the last one who is still working for Google, is departing Google, and will start a company after taking time off.
4. Jul 12, Elon Musk announced [xAI](https://x.ai/), is to understand the true nature of the universe. The new team members have previously worked at DeepMind, OpenAI, Google Research, Microsoft Research, Tesla, and the University of Toronto. Collectively the team contributed some of the most widely used methods in the field, in particular the Adam optimizer, Batch Normalization, Layer Normalization, and the discovery of adversarial examples. xAI aims at implement AGI by the end of 2029, the due date.
5. Jul 12, [businessinsider reported](https://www.businessinsider.com/ai-could-run-out-text-train-chatbots-chatgpt-llm-2023-7) that UC Berkly prof. Stuart Russell warned that AI developers are "running out of text" to train chatbots at a UN summit, and AI's strategy behind training large language models is "starting to hit a brick wall." It also reported that a group of AI researchers, estimated that machine learning datasets will likely deplete all "high-quality language data" before 2026.
6. Jul 12, Google published a [paper on Nature](https://www.nature.com/articles/s41586-023-06291-2) “Large language models encode clinical knowledge”. The paper proposes a human evaluation framework for model answers along multiple axes including factuality, comprehension, reasoning, possible harm and bias. Using a combination of prompting strategies, Flan-PaLM achieves state-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA3, MedMCQA4, PubMedQA5 and Measuring Massive Multitask Language Understanding (MMLU) clinical topics6), including 67.6% accuracy on MedQA (US Medical Licensing Exam-style questions), surpassing the prior state of the art by more than 17%.
7. Jul 12, Nature published a [paper](https://www.nature.com/articles/s41586-023-06095-4) “Quantum-enhanced Markov chain Monte Carlo”. Researchers have developed a quantum algorithm that can sample from complicated distributions, such as MCMC, arising in several applications. This algorithm is well-suited to current hardware and could ease computational bottlenecks in machine learning, statistical physics, and optimization.
8. Jul 13, [Hashingtonpost reported](https://www.washingtonpost.com/technology/2023/07/13/ftc-openai-chatgpt-sam-altman-lina-khan/) that the Federal Trade Commission has opened an expansive investigation into OpenAI, probing whether the maker of the popular ChatGPT bot has run afoul of consumer protection laws by putting personal reputations and data at risk. The FTC’s demands of OpenAI are the first indication of how it intends to enforce those warnings. If the FTC finds that a company violates consumer protection laws, it can levy fines or put a business under a consent decree, which can dictate how the company handles data. The FTC in its request also asked the company to provide extensive details about its products and the way it advertises them. It also demanded details about the policies and procedures that OpenAI takes before it releases any new product to the public, including a list of times that OpenAI held back a large language model because of safety risks.
9. Jul 14, Meta published a [paper](https://ai.meta.com/research/publications/scaling-autoregressive-multi-modal-models-pretraining-and-instruction-tuning/) “Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning”. The new model, named CM3Leon, is a retrieval-augmented, tokenbased, decoder-only multi-modal language model capable of generating and infilling both text and images. CM3Leon achieves state-of-theart performance in text-to-image generation with 5x less training compute than
comparable methods.


**10 July 2023**
1. Last week, Salesforce released [XGen-7b](https://blog.salesforceairesearch.com/xgen/), which achieves comparable or better results when compared with state-of-the-art open-source LLMs (e.g. MPT, Falcon, LLaMA, Redpajama, OpenLLaMA) of similar model size, and its targeted evaluation on long sequence modeling benchmarks show benefits of our 8K-seq models over 2K- and 4K-seq models. Training cost of $150K on 1T tokens under Google Cloud pricing for TPU-v4.
2. 4th July, according to [iTnews](https://www.itnews.com.au/news/chatgpt-used-in-peer-reviews-of-australian-research-council-grant-applications-597596), ChatGPT is used in peer reviews of Australian Research Council grant applications. However, ARC warns that this could be a breach of confidentiality, and has since released a statement advising peer reviewers not to use AI as part of their assessments.
3. 4th July, OpenAI [announced](https://techcrunch.com/2023/07/06/openai-makes-gpt-4-generally-available/) to make GPT-4 API and Code Interpreter generally available to all paying API users. It also announced a deprecation plan for some old models which will retire in 2024.
4. On 5th July, a group of researchers published a [paper](https://arxiv.org/abs/2307.02053) “FLACUNA: Unleashing the Problem-Solving Power of VICUNA using FLAN Fine-Tuning”. The researchers constructed a new dataset comprising a large number of tasks that demand problem-solving skills. Experimental findings strongly indicate that the enhanced problem-solving abilities of  FLACUNA, are obtained through fine-tuning VICUNA on the FLAN dataset, leading to significant improvements across numerous benchmark datasets in INSTRUCTEVAL.
5. 5th July, Nature published a [paper](https://www.nature.com/articles/s41586-023-06185-3) “Accurate medium-range global weather forecasting with 3D neural networks”. The authors of the paper proposed that three-dimensional deep neural networks can be trained to forecast global weather patterns, including extreme weather, with accuracy greater than or equal to that of the best numerical weather prediction models.
6. 5th July, researchers from Microsoft published a [paper](https://arxiv.org/abs/2307.02486#:~:text=In%20this%20work%2C%20we%20introduce%20LongNet%2C%20a%20Transformer,the%20attentive%20field%20exponentially%20as%20the%20distance%20grows.) “LongNet: Scaling Transformers to 1,000,000,000 Tokens”. LongNet is a Transformer variant that can scale sequence length to more than 1 billion tokens, without sacrificing the performance on shorter sequences. Specifically, we propose dilated attention, which expands the attentive field exponentially as the distance grows.
7. 6th July, Google and others published a [paper](https://arxiv.org/abs/2307.03170#:~:text=To%20tackle%20this%20problem%2C%20we%20introduce%20the%20Focused,space%2C%20enabling%20an%20extension%20of%20the%20context%20length.) “Focused Transformer: Contrastive Training for Context Scaling”. The paper introduces the Focused Transformer (FoT), a technique that employs a training process inspired by contrastive learning. This novel approach enhances the structure of the (key, value) space, enabling an extension of the context length.
8. 7th July,  according to [Washingtontpost](https://www.washingtonpost.com/technology/2023/07/07/chatgpt-users-decline-future-ai-openai/) and [this report](https://www.livemint.com/technology/tech-news/chatgpt-faces-first-ever-monthly-traffic-decline-shows-shift-in-user-preferences-report-11688621775980.html), ChatGPT, the highly popular AI chatbot introduced in November, experienced a decline in its website's monthly traffic and unique visitors for the first time in June, as reported by Similarweb analytics.
9. 10th July, according to [TheVerge](https://www.theverge.com/2023/7/10/23787453/meta-instagram-threads-100-million-users-milestone), Instagram’s Threads app surpasses 100 million users within only 5 day since its release.


**2 July 2023**
1. 23rd Jun, [A16Z’s Shoham interviewed](https://a16z.com/2023/06/23/the-next-token-of-progress-4-unlocks-on-the-generative-ai-horizon/) CEOs from Anthropic, Cohere, Charater.AI, they identified four key innovations: Steering, memory, “arms and legs”, and multimodality; and how these key innovations will evolve over the next 6 to 12 months.
2. 26 Jun, [Wired reports](https://www.wired.com/story/google-deepmind-demis-hassabis-chatgpt/) that DeepMind’s CEO says its next AI project Gemini, is still under development within several months, will be more capable than OpenAI’s ChatGPT, including such as planning or the ability to solve problems. AlphaGo-type techniques will be introduced in Gemini. The project could cost hundreds of millions of dollars, while GPT-4 cost more than $100 million, [according to Altman](https://www.wired.com/story/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over/).
3. 26 Jun, [VentureBeat, Databricks is acquiring MosaicML](https://venturebeat.com/data-infrastructure/databricks-is-acquiring-mosaicml-for-a-jaw-dropping-1-3-billion/) for a jaw-dropping $1.3 billion. The news was also confirmed by both Databricks and MosaicLM, an AI start-up established only one and a half years. MosaicLM believes that every organization should be able to benefit from the AI revolution with more control over how their data is used. MosaicLM has its own open-source [MPT serious LLMs](https://github.com/mosaicml/llm-foundry).
4. 27 Jun, Microsoft [published a paper](https://arxiv.org/pdf/2306.14824.pdf): “KOSMOS-2: Grounding Multimodal Large Language Models to the World”. KOSMOS-2 is a multimodal LLM, enabling new capabilities of perceiving object descriptions and grounding text to the visual world. Researchers also created a large-scale dataset of grounded image-text pairs to train the model. The research lays out the foundation for the development of Embodiment AI.
5. 27 Jun, [Nvidia](https://blogs.nvidia.com/blog/2023/06/27/generative-ai-debut-mlperf/),  H100 GPUs set new records on all eight tests in the latest MLPerf training benchmarks released today, excelling on a new MLPerf test for generative AI. On a commercially available cluster of 3,584 H100 GPUs co-developed by startup Inflection AI and operated by CoreWeave, a cloud service provider specializing in GPU-accelerated workloads, the system completed the massive GPT-3-based training benchmark in less than eleven minutes.
6. 28 Jun, [Meta published a paper](https://arxiv.org/pdf/2306.15595.pdf): “Extending Context Window of Large Language Models via Positional Interpolation”. Researchers present Position Interpolation (PI) that extends the context window sizes of RoPE-based pretrained LLMs such as LLaMA models to up to 32768 with minimal fine-tuning (within 1000 steps), while demonstrating strong empirical results on various tasks that require long context, including passkey retrieval, language modeling, and long document summarization from LLaMA 7B to 65B.
7. 29 Jun, [Oracle CEO said](https://finance.yahoo.com/news/oracle-spending-billions-nvidia-chips-224222975.html?guccounter=1) the company is spending "billions" of dollars on chips from Nvidia Corp as it expands a cloud computing service targeting a new wave of artificial intelligence (AI) companies, also including investment on CPUs.
8. 29 Jun, [Inflection.ai, Microsoft-backed start-up, has raised $1.3 billion](https://www.reuters.com/technology/inflection-ai-raises-13-bln-funding-microsoft-others-2023-06-29/) new funding. "We'll be building a cluster of around 22,000 H100s. This is approximately three times more compute than what was used to train all of GPT4. Speed and scale are what's going to really enable us to build a differentiated product," Suleyman said at Collision Conference on Thursday.
9. 2nd July, [OpenChat](https://github.com/imoneoi/openchat), based on LLaMA-13B, ranked #1 open source LLM on [AlpacaEval leaderboard](https://tatsu-lab.github.io/alpaca_eval/). OpenChat is finetuned with 8xA100 80GB GPUs.


**25 June 2023**
1. GitHub CEO [Dohmke says Copilot](https://www.freethink.com/robots-ai/github-copilot#:~:text=GitHub%20CEO%20says%20Copilot%20will%20write%2080%25%20of%20code%20%E2%80%9Csooner,the%20future%20of%20innovation%20itself.&text=Over%20the%20last%20fifteen%20years,of%20the%20world%20of%20coding.) will write 80% of code “sooner than later”, and that doesn’t mean the developer is going to replace. He also said that Copilot brings the fun back, it brings the creativity back, it brings the flow back.
2. 20th June, Microsoft [published a paper](https://arxiv.org/pdf/2306.11644.pdf) “Textbooks Are All You Need”. Researchers trained a transformer-based model phi-1 with 1.3B parameters trained for 4 days on 8 A100 GPUs, using a selection of textbook quality data from the Web(6B tokens). Phi-1 attains pass@1 accuracy 50.6% on HumanEval and 55.5% on MBPP.
3. 20th June, UC Berkeley researcher announced [vLLM](https://vllm.ai/), an easy, fast and cheap LLM. vLLM equipped with PagedAttention redefines the new state of the art in LLM serving: it delivers up to 24x higher throughput than HuggingFace Transformers, without requiring any model architecture changes. ([Github](https://github.com/vllm-project/vllm))
4. 21st June, [GPT-Engineer is launched on GitHub](https://github.com/AntonOsika/gpt-engineer). GPT Engineer is made to be easy to adapt, extend, and make your agent learn how you want your code to look. It generates an entire codebase based on a prompt. It gains over 30K stars after 4 days.
5. 21st June, George Hotz in [a video said](https://www.latent.space/p/geohot#details) that “so GPT-4 is 220 billion in each head, and then it's an eight-way mixture model. So mixture models are what you do when you're out of ideas. So, you know, it's a mixture model. They just train the same model eight times, and then they have some little trick. They actually do 16 inferences, but no, it's not like- [00:43:45]”
6. 21st June, CNBC, [Google accuses Microsoft](https://www.cnbc.com/2023/06/21/google-accuses-microsoft-of-anticompetitive-practices-in-azure-cloud.html) of using stringent licensing terms to exert monopolistic control over the cloud market.
7. 21st June, [CVPR announced best paper awards](https://www.prnewswire.com/news-releases/cvpr-2023-best-paper-award-winners-announced-301857429.html), best papers: “[Visual Programming: Compositional visual reasoning without training](https://c212.net/c/link/?t=0&l=en&o=3900096-1&h=85460982&u=https%3A%2F%2Farxiv.org%2Fabs%2F2211.11559&a=Visual+Programming%3A+Compositional+visual+reasoning+without+training)”, and “[Planning-oriented Autonomous Driving](https://c212.net/c/link/?t=0&l=en&o=3900096-1&h=2174741114&u=https%3A%2F%2Farxiv.org%2Fabs%2F2212.10156&a=Planning-oriented+Autonomous+Driving)”. Best student paper: “ [3D Registration with Maximal Cliques](https://c212.net/c/link/?t=0&l=en&o=3900096-1&h=152672617&u=https%3A%2F%2Farxiv.org%2Fabs%2F2305.10854&a=3D+Registration+with+Maximal+Cliques)”
8. 22nd June, researchers from MIT and Microsoft [published a paper](https://arxiv.org/pdf/2306.09896.pdf) “Demystifying GPT self-Repair for Code Generation”. They found that “the effectiveness of self-repair is only seen in GPT-4”.
9. 22nd June, LMSYS updated the [leaderboard](https://lmsys.org/blog/2023-06-22-leaderboard/). GPT-4, GPT-3.5-Turbo and Claude-v1 are the top three on the list. The top OSS models are Vicuna-33B, WizardLM-33B, and Guanaco-33B. Falcon-40B  is ranked far below in the list, even below Vicuna-7B model.
10. 22nd June, Stability.ai launched [SDXL 0.9](https://stability.ai/blog/sdxl-09-stable-diffusion), a leap forward in AI image generation. The 0.9 version is the most advanced development in the Stable Diffusion text-to-image suite of models, and can produce massively improved image and composition detail over its predecessor.
11. 22nd June, According to CNBC, [AWS is investing $100 million](https://www.cnbc.com/2023/06/22/aws-invests-100-million-in-generative-ai-as-it-sees-a-long-race-ahead.html) in generative A.I. center in race to keep up with Microsoft and Google.
12. 22nd June,  [ MosaicML released MPT-30B](https://thenewstack.io/mosaicml-launches-30b-model-takes-on-llama-falcon-and-gpt/), ranked the same as Vicuan-13B. The company claims that it surpasses OpenAI’s GPT-3 in quality, despite having about 1/6th the number of parameters (GPT-3 has 175 billion). “This means MPT-30B is easier to run on local hardware and much cheaper to deploy for inference”
13. 22nd June, researchers from MIT and Stanford [published a paper](https://arxiv.org/pdf/2306.12672.pdf) “From Word Models to World Models”. The paper proposed rational meaning construction, a computational framework for language-informed thinking that combines neural models of language with probabilistic models for rational inference.
14. 23rd June, [A team of researchers](https://nbcmontana.com/news/local/um-um-western-researchers-find-openais-gpt-4-outperforms-humans-in-creativity-tests), including professors from the University of Montana and UM Western, have found that OpenAI's GPT-4 scored in the top 1% on the Torrance Tests of Creative Thinking (TTCT), matching or outperforming humans in the creative abilities of fluency, flexibility, and originality.
15. 23rd June, [Microsoft says](https://www.independent.co.uk/tech/quantum-computing-microsoft-supercomputer-ibm-b2362174.html) it has announced plans to build a quantum supercomputer after researchers said the next-generation machines will be able to outperform standard computers within the next two years.


**18 June 2023**
1.	Andrew Ng and Geoff Hinton had an [insightful conversation](https://www.linkedin.com/posts/andrewyng_had-an-insightful-conversation-with-geoff-activity-7073688821803978752-DO9h/?trk=public_profile_share_view). They want to share (i) It's important that AI scientists reach consensus on risks-similar to climate scientists, who have rough consensus on climate change-to shape good policy.
(ii) Do AI models understand the world? We think they do. If we list out and develop a shared view on key technical questions like this, it will help move us toward consensus on risks.
2.	On 12 June 2017, Google published its outstanding paper: “[Attention is All You Need](https://arxiv.org/abs/1706.03762)” which introduced the transformer structure – an essential element widely used in nearly all large deep learning models, both in NLP and Computer Vision. The paper has been cited over 75K, and of eight authors, only one still working in Google.
3.	A new LLM evaluation [leaderboard](https://declare-lab.net/instruct-eval/) is released by researchers from UTD Singapore. The proposed model evaluated three features of LLMs: Problem-Solving, Writing, and Alignment (Harmless, Honesty and Helpfulness)
4.	On 13th June, [MetaAI announced I-JEPA](https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa/), the first AI model based on Yann LeCun’s vision for more human-like AI, which is to create machines that can learn internal models of how the world works so that they can learn much more quickly, plan how to accomplish complex tasks, and readily adapt to unfamiliar situations.
5.	On 14th June, [OpenAI released new GPT-4 and GPT-3.5 Turbo](https://twitter.com/OfficialLoganK/status/1668668826047721494) models with 1) function calling in the API (plugins); 2) 16K context 3.5 Turbo model available to everyone; 3) 75% price reduction on v2 embedding models.
6.	McKinsey released “[The economic potential of generative AI: The next productivity frontier](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier#business-value)”. 1) Generative AI could add $2.6 to $4.4 Trillion in value to the global ecomony; 2) 75% of the value falls in: Customer operations, marketing and sales, software engineering and R&D; 3) Generative AI will have impact across all industry sectors; 4) 50% today’s work activities could be automated between 2030 and 2060; 5) Generative AI is just beginning.
7.	On 14 June, The sequoia published “[The New Language Model Stack](https://www.sequoiacap.com/article/llm-stack-perspective/)” which describes how companies are bringing AI applications to life. 1) Nearly every company in the Sequoia network is building LLMs into their products; 2) The new stack centers on LLM APIs, retrieval, and orchestration, but open source usage is also growing; 3) Companies want to customize LLMs to their unique context; 4) LLMs need to become more trustworthy (output quality, data privacy, security) for full adoption
8.	On 15th June, Princeton Uni published a paper “[Infinite Photorealistic Worlds using Procedural Generation](https://arxiv.org/pdf/2306.09310.pdf)”. It’s worth noting that Infinigen is entirely procedural: every asset, from shape to texture, is generated from scratch via randomized mathematical rules, using no external source and allowing infinite variation and composition.
9.	 On 16th June, Meta published a paper “[Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale](https://research.facebook.com/publications/voicebox-text-guided-multilingual-universal-speech-generation-at-scale/)”. Voicebox is a non-autoregressive flow-matching model trained to infill speech, given audio context and text, trained on over 50K hours of speech that are neither filtered nor enhanced. Voicebox not outperforms the SOT zero-shot TSS model, but also up to 20 times faster
10.	IBM Makes the [Best Quantum Computer Open to Public](https://analyticsindiamag.com/ibm-makes-the-best-quantum-computer-open-to-public/) - IBM in collaboration with UC Berkeley researchers announced a recent breakthrough experiment which indicates that quantum computers will soon surpass classical computers in practical tasks.


**11 June 2023**
1. OpenAI see traffic soar to Billion mark, achieved a total [847 million user access](https://www.digitalinformationworld.com/2023/06/openai-website-sees-traffic-soar-to.html) in March 2023.
2. [Video-LLaMA](https://github.com/damo-nlp-sg/video-llama), a multi-modal framework that empowers Large Language Models (LLMs) with the capability of understanding both visual and auditory content in the video. Video-LLaMA showcases the ability to perceive and comprehend video content, generating meaningful responses that are grounded in the visual and auditory information presented in the videos.
3. [InstructZero](https://arxiv.org/pdf/2306.03082v1.pdf), is an efficient instruction optimization method for black-box large language models by optimizing a low-dimensional soft prompt applied to an open-source LLM to generate the instruction for the black-box LLM.
4. [Git-Theta](https://arxiv.org/pdf/2306.04529v1.pdf) is a Git extension that aims to provide similar functionality for machine learning model checkpoints by efficiently and meaningfully track a model's version history natively through Git. [Link to the project](https://github.com/r-three/git-theta)
5. A github project named [roop](https://github.com/s0md3v/roop) is recently released. It allows anyone to take a video and replace the face in it with a face of your choice. You only need one image of the desired face. No dataset, no training.
6. Facebook published a [paper](https://arxiv.org/pdf/2306.05284v1.pdf) introducing MusicGen, which can generate high-quality samples, while being conditioned on textual description or melodic features, allowing better controls over the generated output. 
7. [SpQR](https://github.com/vahe1994/spqr)- Sparse-Quantized Representation, is a new compressed format and quantization technique which enables for the first time near-lossless compression of LLMs across model scales, while reaching similar compression levels to previous methods. Require GPU VRAM > 32GB.
8. [MAN](https://arxiv.org/pdf/2306.05399v1.pdf) - Matting Anything Model, can estimate the alpha matte of any target instance with user prompts as boxes, points, or text descriptions for interactive use by incorporating [SAM](https://segment-anything.com/). It further reaches comparable performance to the specialized matting models on multiple benchmarks, and shows superior generalization ability with fewer parameters as a unified image matting model.
9. [Video-ChatGPT](https://arxiv.org/pdf/2306.05424v1.pdf), is a multimodal model that merges a video-adapted visual encoder with a LLM. The model is capable of understanding and generating human-like conversations about videos. [Try it here](https://www.ival-mbzuai.com/video-chatgpt).
10. DeepMind publish a [paper in Nature](https://www.nature.com/articles/s41586-023-06004-9): Faster sorting algorithms discovered using deep reinforcement learning. Researchers trained a new deep reinforcement learning agent, AlphaDev, to formulate a task of finding a better sorting routine at assembly-language level as a single-player game.
11. [Magic](https://magic.dev/), an AI startup company, announced [LTM-1](https://twitter.com/magicailabs/status/1666116935904292869), a prototype of a neural network architecture designed for giant context windows, can handle prompt with 5,000,000 tokens, much larger than GPT-4's 32k tokens.
12. Huggingface released [StarCode+](https://huggingface.co/bigcode/starcoderplus) - is a fine-tuned version of [StarCoderBase](https://huggingface.co/bigcode/starcoderbase) on 600B tokens from the English web dataset [RedefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb) combined with [StarCoderData](https://huggingface.co/datasets/bigcode/starcoderdata) from [The Stack (v1.2)](https://huggingface.co/datasets/bigcode/the-stack) and a Wikipedia dataset. It's trained on 512 Tesla A100 GPUs for 14 days.
13. RedPajama released [SlimPajama](https://www.cerebras.net/blog/slimpajama-a-627b-token-cleaned-and-deduplicated-version-of-redpajama) - the largest extensively deduplicated, multi-corpora, open-source dataset for training large language models. [Github link](https://github.com/Cerebras/modelzoo/tree/main/modelzoo/transformers/data_processing/slimpajama)


**4 June 2023**
1.	Google, Princeton, and Stanford published a [paper](https://arxiv.org/pdf/2305.17126.pdf) “Large Language Models as Tool Makers”. The paper proposed a closed-loop framework referred to as LATMs, which can create their own reusable tools for problem-solving. The project uses GPT-3.5 as tool user, and GPT-4 as tool maker to reduce inference costs.
2.	Nvidia announced [DGX GH200](https://nvidianews.nvidia.com/news/nvidia-announces-dgx-gh200-ai-supercomputer), a supercomputer that is 10 times faster than the current fastest computer in the world. The computer will be used for generative AI language applications. Watch [this](https://www.nvidia.com/en-us/events/computex/) from 60mins for about 1 min. Google, Microsoft, and Meta will be its first users.
3.	Nvidia’s [Neuralangelo project](https://blogs.nvidia.com/blog/2023/06/01/neuralangelo-ai-research-3d-reconstruction/) can now turn 2D video clips into 3D structures and scenes. It literally generates detailed replicas of buildings, sculptures, and real objects from video clips taken on a mobile or camera.
4.	[Statement on AI Risk](https://www.safe.ai/statement-on-ai-risk) has been circulated and signed by a lot. “Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war”
5.	OpenAI publishes a research [paper](https://arxiv.org/abs/2305.20050), “let’s verify step by step”, by using this process supervision approach, the process-supervised model solves 78% of the problem from the MATH test set. It also aims at attack the Hallucination issues of LLMs.
6.	[GPT4Tools](https://github.com/StevenGrove/GPT4Tools) – an open-source tool based on Vicuan (LLaMA), and aims to efficiently enable LLMs to decide, control and utilizing different visual foundation models, allowing users to interact with images during a conversation.
7.	Google, OpenAI, Anthropic, etc published a [paper](https://arxiv.org/pdf/2305.15324.pdf) “Model evaluation for extreme risks”. An evaluation model is created to evaluate extreme risks by looking at dangerous capabilities and alignment as input and to ensure responsible training, responsible deployment, transparency and appropriate security.


**28 May 2023**
1.	Meta published a [paper](https://arxiv.org/abs/2305.11206): LIMA Less is more for Alignment. Use carefully cured 1000 high-quality prompts, LIMA beats Google’s Bard, and GPT-3.5, and just below GPT-4.
2.	On 22nd May, Meta released [Massively Multilingual Speech AI](https://about.fb.com/news/2023/05/ai-massively-multilingual-speech-technology/), a single multilingual speech recognition model which can process more than 1000 languages, compared with the previous 100 languages only.
3.	0n 23rd May, Adobe Photoshop adds [Native AI](https://venturebeat.com/ai/adobe-integrates-generative-ai-directly-into-photoshop-with-new-firefly-capabilities/), unlike other open source software, it’s a commercially safe model, using high-quality images, and without copyright issues.
4.	On 23rd May, Microsoft released [Windows Copilot](https://blogs.windows.com/windowsdeveloper/2023/05/23/bringing-the-power-of-ai-to-windows-11-unlocking-a-new-era-of-productivity-for-customers-and-developers-with-windows-copilot-and-dev-home/) to Windows 11, it also released a list of other plugins that will greatly improve the productivity of developers and Windows users. Also, Bing is powered by GPT-4 now, but with only 5 QA each month only. Microsoft also announced [Data Fabric](https://learn.microsoft.com/en-us/fabric/get-started/microsoft-fabric-overview), an all-in-one analytics solution that covers everything from data movement to data science, Real-Time Analytics, and business intelligence + services, including data lake, data engineering, and data integration, all in one place.
5.	An interesting [feature of Microsoft 365 Copilot](https://www.youtube.com/watch?v=qMGLU-chnLk) for drafting legal contracts during Microsoft Build.
6.	On 23rd May, Google Bard  Image generation go online. Eg, ask bard “show me some fashion hair styles in Australia”. It will show you some hairstyles.
7.	Two more models based on LLAMA: [airoboros](https://www.reddit.com/r/LocalLLaMA/comments/13o6kp8/airoboros13b_98_against_gpt35/) and [Guanaco](https://www.reddit.com/r/LocalLLaMA/comments/13rthln/guanaco_7b_13b_33b_and_65b_models_by_tim_dettmers/). Both are close to GPT-3.5 performance, especially the latter, which is based on [QLora](https://arxiv.org/pdf/2305.14314.pdf).
8.	JPMorgan is developing its [IndexGPT](https://www.cnbc.com/2023/05/25/jpmorgan-develops-ai-investment-advisor.html) to select investments for customers.
9.	[Spellbook](https://www.spellbook.legal/) uses GPT-4 and other large language models to review and suggest terms for users’ contracts, right in Microsoft Word.
10.	On 25th May, [TII](https://www.tii.ae/news/uaes-technology-innovation-institute-launches-open-source-falcon-40b-large-language-model) released Falcon 40B and temporarily ranked #1 on [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard). TTI announced it’s an open-source model, but maybe not.
11.	On 27th May, [a lawyer used ChatGPT](https://www.theverge.com/2023/5/27/23739913/chatgpt-ai-lawsuit-avianca-airlines-chatbot-research) to prepare a case in USA and now has to answer for its bogus citations. At least six cases were just made up by ChatGPT. [The fake cases source? ChatGPT](https://edition.cnn.com/2023/05/27/business/chat-gpt-avianca-mata-lawyers/index.html).
12.	Nvidia released GPU-4 Powered [Voyager](https://arxiv.org/abs/2305.16291), a lifeling learning agent in Minecraft that continuously explores the worlds, acquires diverse skills, and makes novel discuveries without human intervention.


**22 May 2023**
1.	On 13 May, Sam Altman announced on his [Twitter](https://twitter.com/sama/status/1657143368198279168) that “all ChatGPT Plus users getting browsing and plugins over the next week”. The time AI can use tools is coming. A new web-browsing feature is set to allow ChatGPT-Plus users to access real-time information. They will also get access to more than 70 plug-ins on sites including Expedia and Instacart (https://www.businessinsider.com/chatgpt-openai-web-browsing-plug-change-how-we-use-internet-2023-5).
2.	LangGPT — [Empowering everyone to become a prompt expert!](https://community.openai.com/t/langgpt-empowering-everyone-to-become-a-prompt-expert/207880) LangGPT addresses how to write high-quality prompts, which is becoming more akin to programming in the AI ear. The project link is [here](https://github.com/yzfly/LangGPT). 
3.	On 17th May, [Google announced](https://blog.google/technology/developers/google-colab-ai-coding-features/) AI-powered features will add to Colab, and free of charge. The features include code completions, natural language to code generation and even a code-assisting chatbot.
4.	On 18th May, OpenAI [announced ChatGPT app for iOS](https://openai.com/blog/introducing-the-chatgpt-app-for-ios). The ChatGPT app is free to use and syncs users history across devices. It also integrates [Whisper](https://openai.com/research/whisper), an open-source speech-recognition system, enabling voice input. [ChatGPT Plus subscribers](https://openai.com/blog/chatgpt-plus) get exclusive access to [GPT-4’s capabilities](https://openai.com/product/gpt-4), early access to features and faster response times.
5.	OpenAI CEO [calls on government to regulate AI](https://www.msn.com/en-us/news/technology/openai-ceo-calls-on-government-to-regulate-ai/ar-AA1bgSwd) - OpenAI CEO Sam Altman testified before the Senate Judiciary Committee on Tuesday, calling on Congress to pass legislation to regulate AI.
6.	[Drag your GAN](https://vcai.mpi-inf.mpg.de/projects/DragGAN/) – a technology allow one to "drag" any points of the image to precisely reach target points in a user-interactive manner.


**15 May 2023**
1.	[Google.io conference](https://developers.googleblog.com/2023/05/io23-developer-keynote-recap.html) – 1) Introduced PaLM v2 which support Google’s Bard, improved programming coding and dialog quality of Bard, support over 100 language translation, image <-> text generation/analysis, and more; 2) Google search supercharged with AGI, multi-round QA allows following-up question; 3) improved Gmail and Google photos features and others
2.	Anthropic’s [Claude](https://twitter.com/AnthropicAI/status/1656700154190389248?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Etweet) model can process 100K tokens now, more than 3X bigger than GPT-4’s 32K tokens.
3.	Microsoft [announced](https://www.microsoft.com/en-us/microsoft-365/blog/2023/05/09/introducing-the-microsoft-365-copilot-early-access-program-and-new-capabilities-in-copilot/) new capabilities in Copilot, including semantic index, copilot in whiteboard makes Teams meetings and brainstorms more creative and effective; integrate DALL.E  into PowerPoint to automatically generate ppt slides.
4.	OpenAI announced [Shape-E](https://github.com/openai/shap-e), a conditional generative model for 3D assets. Type in text prompts into Shape-E, and the model will produce 3D objects that create better more detailed, and accurate objects.
5.	HuggingFace announced [Transformers Agent](https://huggingface.co/docs/transformers/transformers_agents) – the agent provides a natural language API, which can interpret natural language and use a list of curated tools. The agent dramatically simplifies the process of a pre-trained LLM to call tools. A similar function with [LangChain](https://python.langchain.com/en/latest/index.html) – a framework for developing applications powered by LLM.
6.	Meta announced [ImageBind](https://twitter.com/MetaAI/status/1655989274620358656) – an AI model capable of binding data from six modalities at once, including the 3D shape of an image. [ImageBind](https://ai.facebook.com/blog/imagebind-six-modalities-binding-ai/) outperforms prior individually trained models and helps AI by enabling machines to better analyze many different forms of information together.
7.	OpenAI applied GPT-4 to automatically propose [explanations](https://twitter.com/OpenAI/status/1655982364273831936) for GPT-2’S 300K neurons, and found neurons responding to concepts like similes, “things done correctly”, or expressions of certainty. GitHub link.
8.	IBM announced [Dromedary](https://github.com/IBM/Dromedary), another LLM which uses principle-driven, self-alignment to minimize human supervision, and surpasses the performance of ChatGPT and Alpaca. 


**8 May 2023**
1.	A.I. Is Getting Better at Mind-Reading - [In a recent experiment](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41593-023-01304-9&data=05%7C01%7Cd.zhu%40curtin.edu.au%7Cd3b1a33582834f569baf08db4fb7c304%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638191422898365032%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=ffzeFZDazt0JJRlWoFLNQ1hrIm4IkqODfx5sEXwta20%3D&reserved=0), researchers used large language models to translate brain activity into words. Accuracy can now reach about 83% based the authors’ experiments.
2.	Thursday, Microsoft announced [AI powered Bing plugins](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.bing.com%2Fnew%3Fform%3DMY028Z%26OCID%3DMY028Z&data=05%7C01%7Cd.zhu%40curtin.edu.au%7Cd3b1a33582834f569baf08db4fb7c304%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638191422898365032%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=VjfZIdudGT%2BTwTKZwb0KnetYJK6HWEwdkjiabScyvXc%3D&reserved=0), enable Bing to search/generate multimedia content, and an Action feature coming soon.
3.	Google: ["We have no moat, and neither does OpenAI"](https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.semianalysis.com%2Fp%2Fgoogle-we-have-no-moat-and-neither&data=05%7C01%7Cd.zhu%40curtin.edu.au%7Cd3b1a33582834f569baf08db4fb7c304%7C5a740cd757684d09ae13f706b09fa22c%7C0%7C0%7C638191422898365032%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=%2Fw27hisANe4Xi8QJFxVj9dczbkX8VD85S1zUUiUMqjk%3D&reserved=0). It’s reported that Google is considering to follow the trend of open source of LLM, such as LLAMA. Many startups and company released their AI Chat bot simply based on LLAMA.
